{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import import_ipynb\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense,Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# utility functions\n",
    "# def cut_old(arr, length):\n",
    "#   idx = len(arr)%length\n",
    "#   out = []\n",
    "#   while(idx+length <= len(arr)):\n",
    "#     out.append(arr[idx:idx+length])\n",
    "#     idx += length\n",
    "#   return np.array(out)\n",
    "\n",
    "def cut(arr, length):\n",
    "  ueberhang = len(arr) % length\n",
    "  a = np.array(arr[ueberhang:]).reshape(-1, length)\n",
    "  return a\n",
    "\n",
    "# def loadSong(fName, numTotalSongs = 1):\n",
    "#   fs, data = wavfile.read(inpathTrain + fName)\n",
    "#   all_data = [data]\n",
    "\n",
    "#   if numTotalSongs > 1:\n",
    "#     seed = sum([ord(char) for char in fName])\n",
    "#     random.seed(seed)\n",
    "#     file_nams = random.sample(fileNames[:170], numTotalSongs-1)\n",
    "#     for name in file_nams:\n",
    "#       fs, data1 = wavfile.read(inpathTrain + name)\n",
    "#       all_data.append(data1)\n",
    "\n",
    "#   concatenated_data = np.concatenate(all_data)\n",
    "#   if concatenated_data.ndim > 1:\n",
    "#     mono_data = np.mean(concatenated_data, axis=1, dtype='int16')\n",
    "#   else:\n",
    "#     mono_data = concatenated_data\n",
    "\n",
    "#   return mono_data.astype('int16')\n",
    "\n",
    "def loadSong(fName, numTotalSongs=1):\n",
    "  fs, data = wavfile.read(inpathTrain + fName)\n",
    "  \n",
    "  if numTotalSongs > 1:\n",
    "      seed = sum(ord(char) for char in fName)\n",
    "      random.seed(seed)\n",
    "      file_nams = random.sample(fileNames[:170], numTotalSongs - 1)\n",
    "      for name in file_nams:\n",
    "          fs, data1 = wavfile.read(inpathTrain + name)\n",
    "          data = np.concatenate((data, data1), axis=0)\n",
    "  \n",
    "  if data.ndim > 1:\n",
    "    mono_data = np.mean(data, axis=1, dtype='int16')\n",
    "  else:\n",
    "    mono_data = data\n",
    "\n",
    "  return mono_data.astype('int16')\n",
    "\n",
    "\n",
    "\n",
    "def loadSongCut(fName, silence_prob = 0, numTotalSongs = 1, percentage_of_song = 1):\n",
    "  data = loadSong(fName, numTotalSongs)\n",
    "  data = cut(data, snippitLength)\n",
    "\n",
    "  # Replace rows with silence based on silence_prob\n",
    "  if silence_prob!=0:\n",
    "    num_rows = data.shape[0]\n",
    "    num_silence_rows = int(num_rows * silence_prob)\n",
    "    silence_rows = np.zeros((num_silence_rows, data.shape[1]), dtype='int16')\n",
    "    data[:num_silence_rows, :] = silence_rows\n",
    "\n",
    "  scaler[fName] = MinMaxScaler()\n",
    "  #data = quadratic_scaler(data, 5)\n",
    "  data = scaler[fName].fit_transform(data)\n",
    "\n",
    "  Xt, Xv = train_test_split(data, test_size=0.3, random_state=42)\n",
    "  Xt = np.array(Xt)\n",
    "  Xv = np.array(Xv)\n",
    "  if percentage_of_song != 1:\n",
    "    index_t = int(len(Xt)*percentage_of_song)\n",
    "    index_v = int(len(Xv)*percentage_of_song)\n",
    "    Xt = Xt[:index_t]\n",
    "    Xv = Xv[:index_v]\n",
    "  return np.array(Xt), np.array(Xv)\n",
    "\n",
    "\n",
    "\n",
    "def snipLoss(y_true, y_pred):\n",
    "  snipWeight = tf.convert_to_tensor([int(np.cosh(x)) for x in range(-5, 5, snippitLength)], dtype='float32')\n",
    "  squared_difference = math_ops.squared_difference(y_true, y_pred)\n",
    "  loss = math_ops.Mul(x = squared_difference, y = snipWeight)\n",
    "  loss = math_ops.log1p(loss)\n",
    "  return loss\n",
    "\n",
    "\n",
    "\n",
    "def si_snr(original, estimate):\n",
    "  # original and estimate are tensors of shape (batch_size, time_steps)\n",
    "  # compute the dot product of original and estimate along the time axis\n",
    "  dot = tf.reduce_sum(original * estimate, axis=-1, keepdims=True)\n",
    "  denominator = tf.reduce_sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * tf.math.log(tf.reduce_sum(scaled_target ** 2, axis=-1) / tf.reduce_sum(e_noise ** 2, axis=-1)) / tf.math.log(10.0)\n",
    "  # return the SI-SNR tensor of shape (batch_size,)\n",
    "  return si_snr\n",
    "\n",
    "\n",
    "\n",
    "def si_snr_std(original, estimate):\n",
    "  dot = np.sum(original * estimate, axis=-1, keepdims=True)\n",
    "  # compute the energy of target along the time axis\n",
    "  denominator = np.sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * np.log10(np.sum(scaled_target ** 2, axis=-1) / np.sum(e_noise ** 2, axis=-1))\n",
    "  # return the SI-SNR array of shape (batch_size,)\n",
    "  return si_snr\n",
    "\n",
    "\n",
    "Xt, Xv = loadSongCut('1728_schubert_op114_3.wav', numTotalSongs = 17, percentage_of_song = float(1/17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46663506, 0.46573283, 0.46715126, ..., 0.56058501, 0.56289272,\n",
       "        0.56517864],\n",
       "       [0.59823792, 0.59385882, 0.59115825, ..., 0.47456973, 0.47299641,\n",
       "        0.47066574],\n",
       "       [0.59262771, 0.58372903, 0.57340324, ..., 0.591302  , 0.59608342,\n",
       "        0.60210804],\n",
       "       ...,\n",
       "       [0.59112639, 0.5870133 , 0.58416746, ..., 0.60457668, 0.60336918,\n",
       "        0.60191428],\n",
       "       [0.59950219, 0.5945315 , 0.59131713, ..., 0.51327468, 0.51274045,\n",
       "        0.51224521],\n",
       "       [0.57556003, 0.56410256, 0.55115983, ..., 0.64320445, 0.65178675,\n",
       "        0.65860653]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  plot history\n",
    "\n",
    "def plot_loss(ax, network_history):\n",
    "    loss = np.concatenate([network_history[key].history['loss'] for key in network_history.keys()])\n",
    "    val_loss = np.concatenate([network_history[key].history['val_loss'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss')\n",
    "    ax.plot(loss, label='Training')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_si_snr(ax, network_history):\n",
    "    si_snr = np.concatenate([network_history[key].history['si_snr'] for key in network_history.keys()])\n",
    "    val_si_snr = np.concatenate([network_history[key].history['val_si_snr'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('SI_SNR')\n",
    "    ax.set_title('SI-SNR')\n",
    "    ax.plot(si_snr, label='Training')\n",
    "    ax.plot(val_si_snr, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_history(network_history, name):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=False)\n",
    "\n",
    "    plot_loss(ax[0], network_history)\n",
    "    plot_si_snr(ax[1], network_history)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name)\n",
    "    # plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  buildModel (Hyperparameter grid search)\n",
    "\n",
    "def buildModel(compression_ratio = 0.5, numDense = 1, numConv = 8, numConvLayer = 0, loss_fct = snipLoss, use_bias = False, learning_rate = 0.001):\n",
    "  \n",
    "  latentSize = int(compression_ratio*snippitLength)\n",
    "\n",
    "  # keep tensorflow from allocating more memory as it currently needs\n",
    "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "  for i in physical_devices:\n",
    "      tf.config.experimental.set_memory_growth(i, True)\n",
    "  tf.device('/device:GPU:0')\n",
    "\n",
    "  input = Input(shape=(snippitLength,1))\n",
    "  x = input\n",
    "\n",
    "  # Convolutional part of encoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(2, padding = 'same')(x)\n",
    "\n",
    "  convShape = x.shape\n",
    "  # calculate flatten dimension\n",
    "  flsize = 1\n",
    "  for i in x.shape:\n",
    "    if(i != None):\n",
    "      flsize*= i\n",
    "  x = Flatten()(x)\n",
    "\n",
    "  # Dense part of encoder\n",
    "  denses = [int(i) for i in np.linspace(flsize, latentSize, numDense+1)]\n",
    "  print(denses)\n",
    "  print(flsize)\n",
    "  print(latentSize)\n",
    "  for i in denses[1:]:\n",
    "    x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "    \n",
    "  encoded = x\n",
    "\n",
    "  # Dense part of decoder\n",
    "  x = encoded\n",
    "  for i in denses[::-1][1:]:\n",
    "    if(numConvLayer == 0 and i == snippitLength):\n",
    "      x = Dense(i, activation='sigmoid')(x)\n",
    "    else:\n",
    "      x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "\n",
    "  if(numConvLayer == 0):\n",
    "    decoded = x\n",
    "\n",
    "  x = Reshape(convShape[1:])(x)\n",
    "\n",
    "  # Convolutional part of decoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv,5, activation='relu', padding='same')(x)\n",
    "    x = UpSampling1D(2)(x)\n",
    "  if(numConvLayer != 0):\n",
    "    decoded = Conv1D(1,5, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "  autoencoder = Model(input, decoded)\n",
    "  autoencoder = Model(input, Flatten()(decoded))\n",
    "\n",
    "  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fct, metrics=[si_snr])\n",
    "  \n",
    "  print(f'current model: ratio={compression_ratio},numDense={numDense},numConv={numConv},numConvLayer={numConvLayer}')\n",
    "  autoencoder.summary()\n",
    "  return autoencoder\n",
    "\n",
    "get_custom_objects()['snipLoss'] = snipLoss\n",
    "get_custom_objects()['si_snr'] = si_snr\n",
    "\n",
    "# testing:\n",
    "# Xt, Xv = loadSongCut('1727_schubert_op114_2.wav')\n",
    "# buildModel(numDense=1).fit(Xt[:2], Xt[:2],\n",
    "#             epochs=1,\n",
    "#             batch_size=512,\n",
    "#             shuffle=True,\n",
    "\n",
    "#             validation_data=(Xv[:2], Xv[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  evaluate Songs\n",
    "\n",
    "def evaluateTestSongs(autoencoder, num = 0):\n",
    "  test_evaluated = []\n",
    "  if num!=0:\n",
    "    numTestSongs = num\n",
    "  print(f'evaluating {numTestSongs} test songs')\n",
    "  for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n",
    "      orig = loadSong(songname)\n",
    "      origSnip = cut(orig, snippitLength)\n",
    "      orig = np.concatenate(origSnip)\n",
    "      \n",
    "      if(songname in scaler.keys()):\n",
    "        scaler_Example = scaler[songname]\n",
    "        origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "      else:\n",
    "        scaler_Example = MinMaxScaler()\n",
    "        origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "      # autoencode song\n",
    "      a = autoencoder.predict(origSnip_transformed)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      XpredSnip = scaler_Example.inverse_transform(a)\n",
    "      estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "\n",
    "      silence = np.zeros((1,snippitLength), dtype = 'int16')\n",
    "      a = scaler_Example.transform(silence)\n",
    "      a = autoencoder.predict(a)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "      # remove noise generated by silence\n",
    "      XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "      Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "\n",
    "      test_loss, test_si_snr_uncorr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed, verbose=2)\n",
    "      \n",
    "      test_si_snr_corrected = si_snr_std(orig, Xpred)\n",
    "      output_wav_name = f'{Test_Song}_{name}_{compression_ratio:.1f}_SNR={test_si_snr_corrected:.1f}.wav'\n",
    "      wavfile.write(f'{output_folder}{Test_Song}.wav', samplerate, orig)\n",
    "      wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "      print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "      test_evaluated.append([songname, test_loss, test_si_snr_uncorr, test_si_snr_corrected])\n",
    "  return test_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  waveform plots\n",
    "#####  predict test song and save it\n",
    "\n",
    "def plotWave(autoencoder, name, compression_ratio, Test_Song = None):\n",
    "  if Test_Song == None:\n",
    "    Test_Song = fileNames[-1]\n",
    "  # exampleSong = name\n",
    "  # exampleSong = '1727_schubert_op114_2.wav'\n",
    "  orig = loadSong(Test_Song)\n",
    "  origSnip = cut(orig, snippitLength)\n",
    "  orig = np.concatenate(origSnip)\n",
    "\n",
    "  if(Test_Song in scaler.keys()):\n",
    "    scaler_Example = scaler[Test_Song]\n",
    "    origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "  else:\n",
    "    scaler_Example = MinMaxScaler()\n",
    "    origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "  # autoencode song\n",
    "  a = autoencoder.predict(origSnip_transformed)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  XpredSnip = scaler_Example.inverse_transform(a)\n",
    "  estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "  silence = np.zeros((1, snippitLength), dtype = 'int16')\n",
    "  a = scaler_Example.transform(silence)\n",
    "  a = autoencoder.predict(a)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "  # remove noise generated by silence\n",
    "  # XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n",
    "  XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "  Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "  estimate_corr = Xpred\n",
    "\n",
    "  # test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed)\n",
    "  si_snr_uncorr = si_snr_std(orig, estimate_uncorr)\n",
    "  print(f'ucorrected SI-SNR = {si_snr_uncorr} dB')\n",
    "\n",
    "  si_snr_corr = si_snr_std(orig, estimate_corr)\n",
    "  print(f'corrected SI-SNR = {si_snr_corr} dB')\n",
    "\n",
    "\n",
    "  # output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n",
    "  output_wav_name = f'{Test_Song}_{name}_{compression_ratio:.1f}_SNR={si_snr_corr:.1f}.wav'\n",
    "  wavfile.write(f'{output_folder}{Test_Song}.wav', samplerate, orig)\n",
    "  wavfile.write(f'{output_folder}UNCORR_{output_wav_name}', samplerate, Xpred)\n",
    "  wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "  print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "\n",
    "  ###### plots\n",
    "  plt.plot(orig, linewidth = 0.1)\n",
    "  plt.plot(orig-Xpred, linewidth = 0.1)\n",
    "  plt.savefig(name + \"whole.pdf\")\n",
    "  plt.clf()\n",
    "  ####################################\n",
    "  #####  see difference in waveform detailed\n",
    "  nrows = 2\n",
    "  ncols = 6\n",
    "  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_corrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      # ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_notcorrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "# model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "# plotWave(autoencoder, f'{output_folder}train_compression_rates/model_0.2_1_96_3wave_', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_histories_from_csv(file_path):\n",
    "    histories = {}\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            filename = row[0]\n",
    "            loss = float(row[1])\n",
    "            val_loss = float(row[2])\n",
    "            histories[filename] = {'loss': [loss], 'val_loss': [val_loss]}\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# drive.mount('/content/drive')\n",
    "# inpathTrain = \"/content/drive/MyDrive/Machine Learning/Autoencoder/train_data/\"\n",
    "# inpathOut = \"/content/drive/MyDrive/Machine Learning/Autoencoder/output/\"\n",
    "inpathTrain = \"songs/wav/\"\n",
    "output_folder = \"output/Versuch_new/\"\n",
    "fileNames = os.listdir(inpathTrain)\n",
    "random.seed(42)\n",
    "fileNames = random.sample(fileNames, len(fileNames))\n",
    "\n",
    "hyperparamsearch_folder = output_folder + 'hyperparamsearch'\n",
    "train_compression_rates_folder = output_folder + 'train_compression_rates'\n",
    "\n",
    "if not os.path.exists(hyperparamsearch_folder):\n",
    "    os.mkdir(hyperparamsearch_folder)\n",
    "\n",
    "if not os.path.exists(train_compression_rates_folder):\n",
    "    os.mkdir(train_compression_rates_folder)\n",
    "\n",
    "scaler = {}\n",
    "\n",
    "# global variables\n",
    "samplerate = 44_100\n",
    "snippitLength = 64\n",
    "\n",
    "loss_fct = snipLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated time = 0.4 h (9 sets)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space = {'compression_ratio' : [0.1, 0.2, 0.3, 0.4],\n",
    "               'numDense' : [3, 4, 5, 6],\n",
    "               'numConv' : [8, 16],\n",
    "               'numConvLayer' : [0, 1, 2]}\n",
    "\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : np.linspace(0.1,0.9,2),\n",
    "#                'numDense' : [2, 3],\n",
    "#                'numConv' : [8, 6],\n",
    "#                'numConvLayer' : np.linspace(0.1,0.2,2)} # small 1\n",
    "# param_space = {'compression_ratio' : [0.1, 0.2],\n",
    "#                'numDense' : [3,4],\n",
    "#                'numConv' : [4, 8],\n",
    "#                'numConvLayer' : [0, 1]} # small 2\n",
    "\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [2, 3, 4, 5, 6],\n",
    "               'numConv' : [8, 16, 24, 32],\n",
    "               'numConvLayer' : [0, 1, 2, 3, 4]}\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [2, 3, 4],\n",
    "               'numConv' : [32, 64],  # 128 too much memory need\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [32, 64],  # 128 too much memory need\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [64, 96, 128],\n",
    "               'numConvLayer' : [4, 6]}\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : [0.2],\n",
    "#                'numDense' : [5, 6],\n",
    "#                'numConv' : [24, 32],\n",
    "#                'numConvLayer' : [ 3, 4]}\n",
    "\n",
    "#### test #####\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [64, 96, 128],\n",
    "               'numConvLayer' : [1, 2, 3]}\n",
    "\n",
    "\n",
    "\n",
    "value_combis = itertools.product(*[v for v in param_space.values()])\n",
    "param_combis = []\n",
    "for combi in value_combis:\n",
    "  param_combi = {key: value for key, value in zip(param_space.keys(), combi)}\n",
    "  if param_combi['numConvLayer'] == 0:\n",
    "    param_combi['numConv'] = 0\n",
    "  param_combis.append(param_combi)\n",
    "\n",
    "# param_combis = [\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 2}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 3}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2}, # 48.5\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}, # 48.5\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 2}, # 49.6\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 3}] # 49.6\n",
    "\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "# param_combis = [\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 4},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 5},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 6}]\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "numHyperEpochs = 1\n",
    "\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "numHyperTrainSongs = 120\n",
    "numHyperTrainSongs = 170\n",
    "# numHyperTrainSongs = 170\n",
    "# numHyperEpochs = 10\n",
    "\n",
    "# param_combis = param_combis[5:]\n",
    "time_per_combi = 2.6\n",
    "print(f'estimated time = {time_per_combi*len(param_combis)/60:.1f} h ({len(param_combis)} sets)')\n",
    "\n",
    "param_combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 12]\n",
      "2048\n",
      "12\n",
      "current model: ratio=0.2,numDense=1,numConv=64,numConvLayer=1\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 64, 64)            384       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 32, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                24576     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              24576     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 32, 64)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 32, 64)            20544     \n",
      "                                                                 \n",
      " up_sampling1d_1 (UpSampling  (None, 64, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 64, 1)             321       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,401\n",
      "Trainable params: 70,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 00:10:44.362762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-07-30 00:10:47.370619: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x3c1e4350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-30 00:10:47.370869: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2023-07-30 00:10:47.449790: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-30 00:10:47.691389: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:530] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-07-30 00:10:47.892685: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2696 - si_snr: 22.3271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 00:10:50.420295: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-30 00:10:50.536179: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-30 00:10:50.538364: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 13s 42ms/step - loss: 0.2696 - si_snr: 22.3271 - val_loss: 0.2423 - val_si_snr: 22.8399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 0.2291 - si_snr: 22.2728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 00:10:56.881081: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-30 00:10:56.881148: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 36ms/step - loss: 0.2291 - si_snr: 22.2728 - val_loss: 0.2105 - val_si_snr: 22.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/52 [======>.......................] - ETA: 1s - loss: 0.2072 - si_snr: 22.3526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:27, 13.94s/it]\n",
      "  0%|          | 0/9 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m idx, filename_train \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(fileNames[:numHyperTrainSongs])):\n\u001b[1;32m     31\u001b[0m   Xt, Xv \u001b[39m=\u001b[39m loadSongCut(filename_train, numTotalSongs \u001b[39m=\u001b[39m numTotalSongs, percentage_of_song \u001b[39m=\u001b[39m percentage_of_song)\n\u001b[0;32m---> 32\u001b[0m   histories[filename_train] \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mfit(Xt, Xt,\n\u001b[1;32m     33\u001b[0m               epochs\u001b[39m=\u001b[39;49mnumHyperEpochs,\n\u001b[1;32m     34\u001b[0m               batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     35\u001b[0m               shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     36\u001b[0m               validation_data\u001b[39m=\u001b[39;49m(Xv, Xv))\n\u001b[1;32m     37\u001b[0m   \u001b[39mdel\u001b[39;00m Xt\n\u001b[1;32m     38\u001b[0m   \u001b[39mdel\u001b[39;00m Xv\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#####  Hyperparameter grid search\n",
    "import stopwatch as sw\n",
    "\n",
    "t = sw.stopwatch(title='gridsearch', time_unit='s')\n",
    "\n",
    "# Load existing results from the JSON file if it exists\n",
    "existing_results = []\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_3epochs.json'\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_1epochs_final.json'\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_new.json'\n",
    "if os.path.exists(existing_file_path):\n",
    "    with open(existing_file_path, 'r') as file:\n",
    "        existing_results = json.load(file)\n",
    "\n",
    "search_results = []\n",
    "model_save_path = output_folder + 'hyperparamsearch/' + f'model.keras'\n",
    "if os.path.exists(model_save_path):\n",
    "    os.remove(model_save_path)\n",
    "\n",
    "for hyperParamSet in tqdm(param_combis):\n",
    "  autoencoder = buildModel(hyperParamSet['compression_ratio'],\n",
    "                           hyperParamSet['numDense'],\n",
    "                           hyperParamSet['numConv'],\n",
    "                           hyperParamSet['numConvLayer'])\n",
    "\n",
    "  histories = {}\n",
    "\n",
    "  t.task('hyperparam')\n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[:numHyperTrainSongs])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numHyperEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv))\n",
    "    del Xt\n",
    "    del Xv\n",
    "    if (idx % int(5/numHyperEpochs) == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "  t.stop()\n",
    "  del autoencoder\n",
    "  tf.keras.backend.clear_session()\n",
    "\n",
    "  pdfname = f'HyperParOpt, compression_ratio= {hyperParamSet[\"compression_ratio\"]:.1f}, numDense= {hyperParamSet[\"numDense\"]}, numConvLayer= {hyperParamSet[\"numConvLayer\"]}, numConv= {hyperParamSet[\"numConv\"]}.pdf'\n",
    "  plot_history(histories, output_folder + 'hyperparamsearch/' + pdfname)\n",
    "\n",
    "  loss = []\n",
    "  val_loss = []\n",
    "  train_si_snr = []\n",
    "  val_si_snr = []\n",
    "  for key in histories.keys():\n",
    "    loss.append(histories[key].history['loss'])\n",
    "    val_loss.append(histories[key].history['val_loss'])\n",
    "    train_si_snr.append(histories[key].history['si_snr'])\n",
    "    val_si_snr.append(histories[key].history['val_si_snr'])\n",
    "  loss         = np.concatenate(loss)\n",
    "  val_loss     = np.concatenate(val_loss)\n",
    "  train_si_snr = np.concatenate(train_si_snr)\n",
    "  val_si_snr   = np.concatenate(val_si_snr)\n",
    "\n",
    "  best_val_epoch    = np.argmax(val_si_snr)\n",
    "  best_val_si_snr   = np.max(val_si_snr)\n",
    "  best_val_loss     = np.min(val_loss)\n",
    "  best_train_si_snr = np.max(train_si_snr)\n",
    "  best_train_loss   = np.min(loss)\n",
    "\n",
    "  search_results.append({\n",
    "    **hyperParamSet,\n",
    "    'best_val_epoch': best_val_epoch,\n",
    "    'best_val_si_snr': best_val_si_snr,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_train_si_snr': best_train_si_snr,\n",
    "    'best_train_loss': best_train_loss\n",
    "  })\n",
    "\n",
    "\n",
    "  latest_results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n",
    "\n",
    "  # Merge existing results and latest results\n",
    "  all_results = existing_results + latest_results\n",
    "\n",
    "  # Write all results to the JSON file\n",
    "  with open(existing_file_path, 'w') as file:\n",
    "      json.dump(all_results, file, indent='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43202943, 0.43355804, 0.42930936, ..., 0.62785079, 0.60562264,\n",
       "        0.58797545],\n",
       "       [0.61044971, 0.60406013, 0.59663287, ..., 0.52762016, 0.49758491,\n",
       "        0.46944998],\n",
       "       [0.56100937, 0.54187975, 0.51704611, ..., 0.61657576, 0.61958491,\n",
       "        0.62178961],\n",
       "       ...,\n",
       "       [0.60083851, 0.58631644, 0.56797398, ..., 0.48204415, 0.48049057,\n",
       "        0.47543098],\n",
       "       [0.44429063, 0.43793584, 0.4264779 , ..., 0.53428268, 0.53460377,\n",
       "        0.53434189],\n",
       "       [0.67353558, 0.66042926, 0.64331356, ..., 0.61247575, 0.61090566,\n",
       "        0.60705211]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter plot\n",
    "from plot_hyperparameter import *\n",
    "hyperparameter_Plot(results, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SI-SNR corrected vs unorrected \n",
    "estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "estimate_corr = Xpred\n",
    "original = orig\n",
    "\n",
    "uncorr = si_snr_std(original, estimate_uncorr)\n",
    "print(f'ucorrected SI-SNR {uncorr} dB')\n",
    "\n",
    "corr = si_snr_std(original, estimate_corr)\n",
    "print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d2 = np.array(original) - 0.1\n",
    "# corr = si_snr_std(original, original_d2)\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d2 = np.array(original) + 1\n",
    "# corr = si_snr_std(original, original_d2)\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d = [i+0.01 for i in original]\n",
    "# corr = si_snr_std(original, np.concatenate(original_d).astype('int16'))\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n",
    "# wavfile.write(output_folder + 'original.wav', samplerate, orig)\n",
    "# wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best model\n",
    "\n",
    "# parSet_sum = {}\n",
    "# for item in search_results:\n",
    "#     numDense = item['numDense']\n",
    "#     numConv = item['numConv']\n",
    "#     numConvLayer = item['numConvLayer']\n",
    "#     best_val_si_snr = item['best_val_si_snr']\n",
    "# \n",
    "#     key = (numDense, numConv, numConvLayer)\n",
    "#     if key in parSet_sum:\n",
    "#        parSet_sum[key] += best_val_si_snr\n",
    "#     else:\n",
    "#         parSet_sum[key] = best_val_si_snr\n",
    "# \n",
    "# keys = [k for k in parSet_sum.keys()]\n",
    "# si_snr_sum = [parSet_sum[k] for k in keys]\n",
    "# bestParSet = keys[np.argmax(si_snr_sum)]\n",
    "# print(f'best set : {bestParSet}')\n",
    "\n",
    "\n",
    "# search_results_json = output_folder + 'hyperparamsearch/' + 'searchResults.json'\n",
    "# search_results_json = 'output/Versuch1_11.07.2023/searchResults.json'\n",
    "# search_results_json = 'output/Versuch3_13.07.2023/hyperparamsearch/searchResults_170songs_5epochs_final.json'\n",
    "# with open(search_results_json, 'r') as file:\n",
    "#     search_results = json.load(file)\n",
    "\n",
    "# compression_rates = np.linspace(0.1,0.9,9)\n",
    "compression_rates = [0.2]\n",
    "# silence_prob = 0.01\n",
    "\n",
    "\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "total_num_songs = len(fileNames)\n",
    "numTopoTrainSongs = int(((total_num_songs*0.7)+1))  # 170\n",
    "numTopoTrainSongs = 50\n",
    "numTopoEpochs = 1\n",
    "\n",
    "numTestSongs = int(total_num_songs*0.3)\n",
    "\n",
    "batch_size = 61\n",
    "learning_rate = 0.00008 #no\n",
    "\n",
    "\n",
    "model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3_zweite.keras' #100\n",
    "histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train_1_96_3.csv'\n",
    "def lr_schedule(epoch):\n",
    "  return learning_rate\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "for c in compression_rates:\n",
    "  # autoencoder = buildModel(c, bestParSet[0],bestParSet[1],bestParSet[2], learning_rate = learning_rate)\n",
    "  autoencoder = buildModel(c, 1, 96, 3, learning_rate = learning_rate)\n",
    "  # autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "  histories = {}\n",
    " \n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[0:numTopoTrainSongs:])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numTopoEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv),\n",
    "                callbacks=[lr_scheduler])\n",
    "    del Xt\n",
    "    del Xv\n",
    "    save_period = int(9/numHyperEpochs)\n",
    "    save_period = 1\n",
    "    if (idx % save_period == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "      # with open(histories_save_path, 'w', newline='') as csvfile:\n",
    "      #     writer = csv.writer(csvfile)\n",
    "      #     writer.writerow(['filename', 'loss', 'val_loss'])\n",
    "      #     for key, value in histories.items():\n",
    "      #         writer.writerow([key, value.history['loss'][0], value.history['val_loss'][0]], value.history['loss'][0])\n",
    "  tf.keras.backend.clear_session()\n",
    "  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n",
    "  \n",
    "  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n",
    "  # histories = read_histories_from_csv(histories_save_path)\n",
    "  plot_history(histories, f'{output_folder}train_compression_rates/{pdfname}')\n",
    "  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n",
    "\n",
    "  testPerformance = evaluateTestSongs(autoencoder, num = 10)\n",
    "\n",
    "  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for row in testPerformance:\n",
    "        writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
