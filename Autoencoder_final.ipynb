{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import import_ipynb\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense,Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# utility functions\n",
    "def cut(arr, length):\n",
    "  idx = len(arr)%length\n",
    "  out = []\n",
    "  while(idx+length <= len(arr)):\n",
    "    out.append(arr[idx:idx+length])\n",
    "    idx += length\n",
    "  return np.array(out)\n",
    "\n",
    "\n",
    "\n",
    "def loadSong(fName, numTotalSongs = 1):\n",
    "  fs, data = wavfile.read(inpathTrain + fName)\n",
    "  all_data = [data]\n",
    "\n",
    "  if numTotalSongs > 1:\n",
    "    seed = sum([ord(char) for char in fName])\n",
    "    random.seed(seed)\n",
    "    file_nams = random.sample(fileNames[:170], numTotalSongs-1)\n",
    "    for name in file_nams:\n",
    "      fs, data1 = wavfile.read(inpathTrain + name)\n",
    "      all_data.append(data1)\n",
    "\n",
    "  concatenated_data = np.concatenate(all_data)\n",
    "  if concatenated_data.ndim > 1:\n",
    "    mono_data = np.mean(concatenated_data, axis=1)\n",
    "  else:\n",
    "    mono_data = concatenated_data\n",
    "\n",
    "  return mono_data.astype('int16')\n",
    "\n",
    "\n",
    "\n",
    "def loadSongCut(fName, silence_prob = 0, numTotalSongs = 1, percentage_of_song = 1):\n",
    "  data = loadSong(fName, numTotalSongs)\n",
    "  data = cut(data, snippitLength)\n",
    "\n",
    "  # Replace rows with silence based on silence_prob\n",
    "  if silence_prob!=0:\n",
    "    num_rows = data.shape[0]\n",
    "    num_silence_rows = int(num_rows * silence_prob)\n",
    "    silence_rows = np.zeros((num_silence_rows, data.shape[1]))\n",
    "    data[:num_silence_rows, :] = silence_rows\n",
    "\n",
    "  scaler[fName] = MinMaxScaler()\n",
    "  #data = quadratic_scaler(data, 5)\n",
    "  data = scaler[fName].fit_transform(data)\n",
    "\n",
    "  Xt, Xv = train_test_split(data, test_size=0.3, random_state=42)\n",
    "  if percentage_of_song != 1:\n",
    "    index_t = int(len(Xt)*percentage_of_song)\n",
    "    index_v = int(len(Xv)*percentage_of_song)\n",
    "    Xt = Xt[:index_t]\n",
    "    Xv = Xv[:index_v]\n",
    "  return np.array(Xt), np.array(Xv)\n",
    "\n",
    "\n",
    "\n",
    "def snipLoss(y_true, y_pred):\n",
    "  snipWeight = tf.convert_to_tensor([int(np.cosh(x)) for x in range(-5, 5, snippitLength)], dtype='float32')\n",
    "\n",
    "  loss = math_ops.squared_difference(y_true,y_pred)\n",
    "  loss = math_ops.Mul(x = loss,y = snipWeight)\n",
    "  loss = math_ops.log1p(loss)\n",
    "  return loss\n",
    "\n",
    "\n",
    "\n",
    "def si_snr(original, estimate):\n",
    "  # original and estimate are tensors of shape (batch_size, time_steps)\n",
    "  # compute the dot product of original and estimate along the time axis\n",
    "  dot = tf.reduce_sum(original * estimate, axis=-1, keepdims=True)\n",
    "  denominator = tf.reduce_sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * tf.math.log(tf.reduce_sum(scaled_target ** 2, axis=-1) / tf.reduce_sum(e_noise ** 2, axis=-1)) / tf.math.log(10.0)\n",
    "  # return the SI-SNR tensor of shape (batch_size,)\n",
    "  return si_snr\n",
    "\n",
    "\n",
    "\n",
    "def si_snr_std(original, estimate):\n",
    "  dot = np.sum(original * estimate, axis=-1, keepdims=True)\n",
    "  # compute the energy of target along the time axis\n",
    "  denominator = np.sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * np.log10(np.sum(scaled_target ** 2, axis=-1) / np.sum(e_noise ** 2, axis=-1))\n",
    "  # return the SI-SNR array of shape (batch_size,)\n",
    "  return si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  plot history\n",
    "\n",
    "def plot_loss(ax, network_history):\n",
    "    loss = np.concatenate([network_history[key].history['loss'] for key in network_history.keys()])\n",
    "    val_loss = np.concatenate([network_history[key].history['val_loss'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss')\n",
    "    ax.plot(loss, label='Training')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_si_snr(ax, network_history):\n",
    "    si_snr = np.concatenate([network_history[key].history['si_snr'] for key in network_history.keys()])\n",
    "    val_si_snr = np.concatenate([network_history[key].history['val_si_snr'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('SI_SNR')\n",
    "    ax.set_title('SI-SNR')\n",
    "    ax.plot(si_snr, label='Training')\n",
    "    ax.plot(val_si_snr, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_history(network_history, name):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=False)\n",
    "\n",
    "    plot_loss(ax[0], network_history)\n",
    "    plot_si_snr(ax[1], network_history)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name)\n",
    "    # plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  buildModel (Hyperparameter grid search)\n",
    "\n",
    "def buildModel(compression_ratio = 0.5, numDense = 1, numConv = 8, numConvLayer = 0, loss_fct = snipLoss, use_bias = False, learning_rate = 0.001):\n",
    "  \n",
    "  latentSize = int(compression_ratio*snippitLength)\n",
    "\n",
    "  # keep tensorflow from allocating more memory as it currently needs\n",
    "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "  for i in physical_devices:\n",
    "      tf.config.experimental.set_memory_growth(i, True)\n",
    "  tf.device('/device:GPU:0')\n",
    "\n",
    "  input = Input(shape=(snippitLength,1))\n",
    "  x = input\n",
    "\n",
    "  # Convolutional part of encoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(2, padding = 'same')(x)\n",
    "\n",
    "  convShape = x.shape\n",
    "  # calculate flatten dimension\n",
    "  flsize = 1\n",
    "  for i in x.shape:\n",
    "    if(i != None):\n",
    "      flsize*= i\n",
    "  x = Flatten()(x)\n",
    "\n",
    "  # Dense part of encoder\n",
    "  denses = [int(i) for i in np.linspace(flsize, latentSize, numDense+1)]\n",
    "  print(denses)\n",
    "  print(flsize)\n",
    "  print(latentSize)\n",
    "  for i in denses[1:]:\n",
    "    x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "    \n",
    "  encoded = x\n",
    "\n",
    "  # Dense part of decoder\n",
    "  x = encoded\n",
    "  for i in denses[::-1][1:]:\n",
    "    if(numConvLayer == 0 and i == snippitLength):\n",
    "      x = Dense(i, activation='sigmoid')(x)\n",
    "    else:\n",
    "      x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "\n",
    "  if(numConvLayer == 0):\n",
    "    decoded = x\n",
    "\n",
    "  x = Reshape(convShape[1:])(x)\n",
    "\n",
    "  # Convolutional part of decoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv,5, activation='relu', padding='same')(x)\n",
    "    x = UpSampling1D(2)(x)\n",
    "  if(numConvLayer != 0):\n",
    "    decoded = Conv1D(1,5, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "  autoencoder = Model(input, decoded)\n",
    "  autoencoder = Model(input, Flatten()(decoded))\n",
    "\n",
    "  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fct, metrics=[si_snr])\n",
    "  \n",
    "  print(f'current model: ratio={compression_ratio},numDense={numDense},numConv={numConv},numConvLayer={numConvLayer}')\n",
    "  autoencoder.summary()\n",
    "  return autoencoder\n",
    "\n",
    "get_custom_objects()['snipLoss'] = snipLoss\n",
    "get_custom_objects()['si_snr'] = si_snr\n",
    "\n",
    "# testing:\n",
    "# Xt, Xv = loadSongCut('1727_schubert_op114_2.wav')\n",
    "# buildModel(numDense=1).fit(Xt[:2], Xt[:2],\n",
    "#             epochs=1,\n",
    "#             batch_size=512,\n",
    "#             shuffle=True,\n",
    "\n",
    "#             validation_data=(Xv[:2], Xv[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  evaluate Songs\n",
    "\n",
    "def evaluateTestSongs(autoencoder, num = 0):\n",
    "  test_evaluated = []\n",
    "  if num!=0:\n",
    "    numTestSongs = num\n",
    "  print(f'evaluating {numTestSongs} test songs')\n",
    "  for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n",
    "      orig = loadSong(songname)\n",
    "      origSnip = cut(orig, snippitLength)\n",
    "      orig = np.concatenate(origSnip)\n",
    "      \n",
    "      if(songname in scaler.keys()):\n",
    "        scaler_Example = scaler[songname]\n",
    "        origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "      else:\n",
    "        scaler_Example = MinMaxScaler()\n",
    "        origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "      # autoencode song\n",
    "      a = autoencoder.predict(origSnip_transformed)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      XpredSnip = scaler_Example.inverse_transform(a)\n",
    "      estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "\n",
    "      silence = np.zeros((1,snippitLength), dtype = 'int16')\n",
    "      a = scaler_Example.transform(silence)\n",
    "      a = autoencoder.predict(a)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "      # remove noise generated by silence\n",
    "      XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "      Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "\n",
    "      test_loss, test_si_snr_uncorr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed, verbose=2)\n",
    "      \n",
    "      test_si_snr_corrected = si_snr_std(orig, Xpred)\n",
    "      output_wav_name = f'{Test_Song}_{name}_{compression_ratio:.1f}_SNR={test_si_snr_corrected:.1f}.wav'\n",
    "      wavfile.write(f'{output_folder}{Test_Song}.wav', samplerate, orig)\n",
    "      wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "      print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "      test_evaluated.append([songname, test_loss, test_si_snr_uncorr, test_si_snr_corrected])\n",
    "  return test_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  waveform plots\n",
    "#####  predict test song and save it\n",
    "\n",
    "def plotWave(autoencoder, name, compression_ratio, Test_Song = None):\n",
    "  if Test_Song == None:\n",
    "    Test_Song = fileNames[-1]\n",
    "  # exampleSong = name\n",
    "  # exampleSong = '1727_schubert_op114_2.wav'\n",
    "  orig = loadSong(Test_Song)\n",
    "  origSnip = cut(orig, snippitLength)\n",
    "  orig = np.concatenate(origSnip)\n",
    "\n",
    "  if(Test_Song in scaler.keys()):\n",
    "    scaler_Example = scaler[Test_Song]\n",
    "    origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "  else:\n",
    "    scaler_Example = MinMaxScaler()\n",
    "    origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "  # autoencode song\n",
    "  a = autoencoder.predict(origSnip_transformed)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  XpredSnip = scaler_Example.inverse_transform(a)\n",
    "  estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "  silence = np.zeros((1, snippitLength), dtype = 'int16')\n",
    "  a = scaler_Example.transform(silence)\n",
    "  a = autoencoder.predict(a)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "  # remove noise generated by silence\n",
    "  # XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n",
    "  XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "  Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "  estimate_corr = Xpred\n",
    "\n",
    "  # test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed)\n",
    "  si_snr_uncorr = si_snr_std(orig, estimate_uncorr)\n",
    "  print(f'ucorrected SI-SNR = {si_snr_uncorr} dB')\n",
    "\n",
    "  si_snr_corr = si_snr_std(orig, estimate_corr)\n",
    "  print(f'corrected SI-SNR = {si_snr_corr} dB')\n",
    "\n",
    "\n",
    "  # output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n",
    "  output_wav_name = f'{Test_Song}_{name}_{compression_ratio:.1f}_SNR={si_snr_corr:.1f}.wav'\n",
    "  wavfile.write(f'{output_folder}{Test_Song}.wav', samplerate, orig)\n",
    "  wavfile.write(f'{output_folder}UNCORR_{output_wav_name}', samplerate, Xpred)\n",
    "  wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "  print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "\n",
    "  ###### plots\n",
    "  plt.plot(orig, linewidth = 0.1)\n",
    "  plt.plot(orig-Xpred, linewidth = 0.1)\n",
    "  plt.savefig(name + \"whole.pdf\")\n",
    "  plt.clf()\n",
    "  ####################################\n",
    "  #####  see difference in waveform detailed\n",
    "  nrows = 2\n",
    "  ncols = 6\n",
    "  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_corrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      # ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_notcorrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "# model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "# plotWave(autoencoder, f'{output_folder}train_compression_rates/model_0.2_1_96_3wave_', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_histories_from_csv(file_path):\n",
    "    histories = {}\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            filename = row[0]\n",
    "            loss = float(row[1])\n",
    "            val_loss = float(row[2])\n",
    "            histories[filename] = {'loss': [loss], 'val_loss': [val_loss]}\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# drive.mount('/content/drive')\n",
    "# inpathTrain = \"/content/drive/MyDrive/Machine Learning/Autoencoder/train_data/\"\n",
    "# inpathOut = \"/content/drive/MyDrive/Machine Learning/Autoencoder/output/\"\n",
    "inpathTrain = \"songs/wav/\"\n",
    "output_folder = \"output/Versuch_new/\"\n",
    "fileNames = os.listdir(inpathTrain)\n",
    "random.seed(42)\n",
    "fileNames = random.sample(fileNames, len(fileNames))\n",
    "\n",
    "hyperparamsearch_folder = output_folder + 'hyperparamsearch'\n",
    "train_compression_rates_folder = output_folder + 'train_compression_rates'\n",
    "\n",
    "if not os.path.exists(hyperparamsearch_folder):\n",
    "    os.mkdir(hyperparamsearch_folder)\n",
    "\n",
    "if not os.path.exists(train_compression_rates_folder):\n",
    "    os.mkdir(train_compression_rates_folder)\n",
    "\n",
    "scaler = {}\n",
    "\n",
    "# global variables\n",
    "samplerate = 44_100\n",
    "snippitLength = 64\n",
    "\n",
    "loss_fct = snipLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated time = 0.4 h (9 sets)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 1},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2},\n",
       " {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space = {'compression_ratio' : [0.1, 0.2, 0.3, 0.4],\n",
    "               'numDense' : [3, 4, 5, 6],\n",
    "               'numConv' : [8, 16],\n",
    "               'numConvLayer' : [0, 1, 2]}\n",
    "\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : np.linspace(0.1,0.9,2),\n",
    "#                'numDense' : [2, 3],\n",
    "#                'numConv' : [8, 6],\n",
    "#                'numConvLayer' : np.linspace(0.1,0.2,2)} # small 1\n",
    "# param_space = {'compression_ratio' : [0.1, 0.2],\n",
    "#                'numDense' : [3,4],\n",
    "#                'numConv' : [4, 8],\n",
    "#                'numConvLayer' : [0, 1]} # small 2\n",
    "\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [2, 3, 4, 5, 6],\n",
    "               'numConv' : [8, 16, 24, 32],\n",
    "               'numConvLayer' : [0, 1, 2, 3, 4]}\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [2, 3, 4],\n",
    "               'numConv' : [32, 64],  # 128 too much memory need\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [32, 64],  # 128 too much memory need\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [64, 96, 128],\n",
    "               'numConvLayer' : [4, 6]}\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : [0.2],\n",
    "#                'numDense' : [5, 6],\n",
    "#                'numConv' : [24, 32],\n",
    "#                'numConvLayer' : [ 3, 4]}\n",
    "\n",
    "#### test #####\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [64, 96, 128],\n",
    "               'numConvLayer' : [1, 2, 3]}\n",
    "\n",
    "\n",
    "\n",
    "value_combis = itertools.product(*[v for v in param_space.values()])\n",
    "param_combis = []\n",
    "for combi in value_combis:\n",
    "  param_combi = {key: value for key, value in zip(param_space.keys(), combi)}\n",
    "  if param_combi['numConvLayer'] == 0:\n",
    "    param_combi['numConv'] = 0\n",
    "  param_combis.append(param_combi)\n",
    "\n",
    "# param_combis = [\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 2}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 3}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3}, #47.8\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2}, # 48.5\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}, # 48.5\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 2}, # 49.6\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 3}] # 49.6\n",
    "\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n",
    "# param_combis = [\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 4},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 5},\n",
    "#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 6}]\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "numHyperEpochs = 1\n",
    "\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "numHyperTrainSongs = 120\n",
    "numHyperTrainSongs = 170\n",
    "# numHyperTrainSongs = 170\n",
    "# numHyperEpochs = 10\n",
    "\n",
    "# param_combis = param_combis[5:]\n",
    "time_per_combi = 2.6\n",
    "print(f'estimated time = {time_per_combi*len(param_combis)/60:.1f} h ({len(param_combis)} sets)')\n",
    "\n",
    "param_combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]2023-07-29 23:28:35.508585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 12]\n",
      "2048\n",
      "12\n",
      "current model: ratio=0.2,numDense=1,numConv=64,numConvLayer=1\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 64, 64)            384       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 32, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                24576     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              24576     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 32, 64)            20544     \n",
      "                                                                 \n",
      " up_sampling1d (UpSampling1D  (None, 64, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 64, 1)             321       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,401\n",
      "Trainable params: 70,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:28:35.658530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:35.658568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:35.662356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:35.662425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:35.662448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:37.001491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:37.001558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:37.001566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-29 23:28:37.001591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 23:28:37.001617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-07-29 23:28:45.758941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-07-29 23:28:48.930608: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x33ce06a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-29 23:28:48.930644: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2023-07-29 23:28:48.975189: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-29 23:28:49.131462: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:530] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-07-29 23:28:49.286728: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2742 - si_snr: 22.3078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:28:51.843148: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-29 23:28:51.953096: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-29 23:28:51.955851: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 9s 40ms/step - loss: 0.2742 - si_snr: 22.3078 - val_loss: 0.2443 - val_si_snr: 22.7877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 0.2341 - si_snr: 22.1177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:29:01.646018: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-29 23:29:01.646118: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 35ms/step - loss: 0.2341 - si_snr: 22.1177 - val_loss: 0.2184 - val_si_snr: 22.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/52 [===========================>..] - ETA: 0s - loss: 0.1837 - si_snr: 23.6136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:29:10.192191: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.80GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - ETA: 0s - loss: 0.1825 - si_snr: 23.6618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:29:10.429675: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-29 23:29:10.429753: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 38ms/step - loss: 0.1825 - si_snr: 23.6618 - val_loss: 0.1297 - val_si_snr: 25.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.0787 - si_snr: 28.3987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:29:17.239185: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-29 23:29:17.675544: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0787 - si_snr: 28.3987 - val_loss: 0.0550 - val_si_snr: 30.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 0.0593 - si_snr: 28.9262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 23:29:26.122360: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.87GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0593 - si_snr: 28.9262 - val_loss: 0.0484 - val_si_snr: 30.2211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0512 - si_snr: 29.3619 - val_loss: 0.0421 - val_si_snr: 30.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 39ms/step - loss: 0.0463 - si_snr: 29.6302 - val_loss: 0.0308 - val_si_snr: 32.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0307 - si_snr: 31.8531 - val_loss: 0.0259 - val_si_snr: 33.2945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:16,  9.55s/it]\n",
      "  0%|          | 0/9 [01:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m t\u001b[39m.\u001b[39mtask(\u001b[39m'\u001b[39m\u001b[39mhyperparam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m idx, filename_train \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(fileNames[:numHyperTrainSongs])):\n\u001b[0;32m---> 31\u001b[0m   Xt, Xv \u001b[39m=\u001b[39m loadSongCut(filename_train, numTotalSongs \u001b[39m=\u001b[39;49m numTotalSongs, percentage_of_song \u001b[39m=\u001b[39;49m percentage_of_song)\n\u001b[1;32m     32\u001b[0m   histories[filename_train] \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mfit(Xt, Xt,\n\u001b[1;32m     33\u001b[0m               epochs\u001b[39m=\u001b[39mnumHyperEpochs,\n\u001b[1;32m     34\u001b[0m               batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     35\u001b[0m               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m               validation_data\u001b[39m=\u001b[39m(Xv, Xv))\n\u001b[1;32m     37\u001b[0m   \u001b[39mdel\u001b[39;00m Xt\n",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m, in \u001b[0;36mloadSongCut\u001b[0;34m(fName, silence_prob, numTotalSongs, percentage_of_song)\u001b[0m\n\u001b[1;32m     46\u001b[0m scaler[fName] \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     47\u001b[0m \u001b[39m#data = quadratic_scaler(data, 5)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m data \u001b[39m=\u001b[39m scaler[fName]\u001b[39m.\u001b[39;49mfit_transform(data)\n\u001b[1;32m     50\u001b[0m Xt, Xv \u001b[39m=\u001b[39m train_test_split(data, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m percentage_of_song \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:514\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 514\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    515\u001b[0m     X,\n\u001b[1;32m    516\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    517\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    518\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    519\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    523\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 120\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2322\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2324\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2325\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#####  Hyperparameter grid search\n",
    "import stopwatch as sw\n",
    "\n",
    "t = sw.stopwatch(title='gridsearch', time_unit='s')\n",
    "\n",
    "# Load existing results from the JSON file if it exists\n",
    "existing_results = []\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_3epochs.json'\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_1epochs_final.json'\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_new.json'\n",
    "if os.path.exists(existing_file_path):\n",
    "    with open(existing_file_path, 'r') as file:\n",
    "        existing_results = json.load(file)\n",
    "\n",
    "search_results = []\n",
    "model_save_path = output_folder + 'hyperparamsearch/' + f'model.keras'\n",
    "if os.path.exists(model_save_path):\n",
    "    os.remove(model_save_path)\n",
    "\n",
    "for hyperParamSet in tqdm(param_combis):\n",
    "  autoencoder = buildModel(hyperParamSet['compression_ratio'],\n",
    "                           hyperParamSet['numDense'],\n",
    "                           hyperParamSet['numConv'],\n",
    "                           hyperParamSet['numConvLayer'])\n",
    "\n",
    "  histories = {}\n",
    "\n",
    "  t.task('hyperparam')\n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[:numHyperTrainSongs])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numHyperEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv))\n",
    "    del Xt\n",
    "    del Xv\n",
    "    if (idx % int(5/numHyperEpochs) == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "  t.stop()\n",
    "  del autoencoder\n",
    "  tf.keras.backend.clear_session()\n",
    "\n",
    "  pdfname = f'HyperParOpt, compression_ratio= {hyperParamSet[\"compression_ratio\"]:.1f}, numDense= {hyperParamSet[\"numDense\"]}, numConvLayer= {hyperParamSet[\"numConvLayer\"]}, numConv= {hyperParamSet[\"numConv\"]}.pdf'\n",
    "  plot_history(histories, output_folder + 'hyperparamsearch/' + pdfname)\n",
    "\n",
    "  loss = []\n",
    "  val_loss = []\n",
    "  train_si_snr = []\n",
    "  val_si_snr = []\n",
    "  for key in histories.keys():\n",
    "    loss.append(histories[key].history['loss'])\n",
    "    val_loss.append(histories[key].history['val_loss'])\n",
    "    train_si_snr.append(histories[key].history['si_snr'])\n",
    "    val_si_snr.append(histories[key].history['val_si_snr'])\n",
    "  loss         = np.concatenate(loss)\n",
    "  val_loss     = np.concatenate(val_loss)\n",
    "  train_si_snr = np.concatenate(train_si_snr)\n",
    "  val_si_snr   = np.concatenate(val_si_snr)\n",
    "\n",
    "  best_val_epoch    = np.argmax(val_si_snr)\n",
    "  best_val_si_snr   = np.max(val_si_snr)\n",
    "  best_val_loss     = np.min(val_loss)\n",
    "  best_train_si_snr = np.max(train_si_snr)\n",
    "  best_train_loss   = np.min(loss)\n",
    "\n",
    "  search_results.append({\n",
    "    **hyperParamSet,\n",
    "    'best_val_epoch': best_val_epoch,\n",
    "    'best_val_si_snr': best_val_si_snr,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_train_si_snr': best_train_si_snr,\n",
    "    'best_train_loss': best_train_loss\n",
    "  })\n",
    "\n",
    "\n",
    "  latest_results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n",
    "\n",
    "  # Merge existing results and latest results\n",
    "  all_results = existing_results + latest_results\n",
    "\n",
    "  # Write all results to the JSON file\n",
    "  with open(existing_file_path, 'w') as file:\n",
    "      json.dump(all_results, file, indent='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter plot\n",
    "from plot_hyperparameter import *\n",
    "hyperparameter_Plot(results, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SI-SNR corrected vs unorrected \n",
    "estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "estimate_corr = Xpred\n",
    "original = orig\n",
    "\n",
    "uncorr = si_snr_std(original, estimate_uncorr)\n",
    "print(f'ucorrected SI-SNR {uncorr} dB')\n",
    "\n",
    "corr = si_snr_std(original, estimate_corr)\n",
    "print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d2 = np.array(original) - 0.1\n",
    "# corr = si_snr_std(original, original_d2)\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d2 = np.array(original) + 1\n",
    "# corr = si_snr_std(original, original_d2)\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# original_d = [i+0.01 for i in original]\n",
    "# corr = si_snr_std(original, np.concatenate(original_d).astype('int16'))\n",
    "# print(f'corrected SI-SNR {corr} dB')\n",
    "\n",
    "# output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n",
    "# wavfile.write(output_folder + 'original.wav', samplerate, orig)\n",
    "# wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best model\n",
    "\n",
    "# parSet_sum = {}\n",
    "# for item in search_results:\n",
    "#     numDense = item['numDense']\n",
    "#     numConv = item['numConv']\n",
    "#     numConvLayer = item['numConvLayer']\n",
    "#     best_val_si_snr = item['best_val_si_snr']\n",
    "# \n",
    "#     key = (numDense, numConv, numConvLayer)\n",
    "#     if key in parSet_sum:\n",
    "#        parSet_sum[key] += best_val_si_snr\n",
    "#     else:\n",
    "#         parSet_sum[key] = best_val_si_snr\n",
    "# \n",
    "# keys = [k for k in parSet_sum.keys()]\n",
    "# si_snr_sum = [parSet_sum[k] for k in keys]\n",
    "# bestParSet = keys[np.argmax(si_snr_sum)]\n",
    "# print(f'best set : {bestParSet}')\n",
    "\n",
    "\n",
    "# search_results_json = output_folder + 'hyperparamsearch/' + 'searchResults.json'\n",
    "# search_results_json = 'output/Versuch1_11.07.2023/searchResults.json'\n",
    "# search_results_json = 'output/Versuch3_13.07.2023/hyperparamsearch/searchResults_170songs_5epochs_final.json'\n",
    "# with open(search_results_json, 'r') as file:\n",
    "#     search_results = json.load(file)\n",
    "\n",
    "# compression_rates = np.linspace(0.1,0.9,9)\n",
    "compression_rates = [0.2]\n",
    "# silence_prob = 0.01\n",
    "\n",
    "\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "total_num_songs = len(fileNames)\n",
    "numTopoTrainSongs = int(((total_num_songs*0.7)+1))  # 170\n",
    "numTopoTrainSongs = 50\n",
    "numTopoEpochs = 1\n",
    "\n",
    "numTestSongs = int(total_num_songs*0.3)\n",
    "\n",
    "batch_size = 61\n",
    "learning_rate = 0.00008 #no\n",
    "\n",
    "\n",
    "model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3_zweite.keras' #100\n",
    "histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train_1_96_3.csv'\n",
    "def lr_schedule(epoch):\n",
    "  return learning_rate\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "for c in compression_rates:\n",
    "  # autoencoder = buildModel(c, bestParSet[0],bestParSet[1],bestParSet[2], learning_rate = learning_rate)\n",
    "  autoencoder = buildModel(c, 1, 96, 3, learning_rate = learning_rate)\n",
    "  # autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "  histories = {}\n",
    " \n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[0:numTopoTrainSongs:])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numTopoEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv),\n",
    "                callbacks=[lr_scheduler])\n",
    "    del Xt\n",
    "    del Xv\n",
    "    save_period = int(9/numHyperEpochs)\n",
    "    save_period = 1\n",
    "    if (idx % save_period == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "      # with open(histories_save_path, 'w', newline='') as csvfile:\n",
    "      #     writer = csv.writer(csvfile)\n",
    "      #     writer.writerow(['filename', 'loss', 'val_loss'])\n",
    "      #     for key, value in histories.items():\n",
    "      #         writer.writerow([key, value.history['loss'][0], value.history['val_loss'][0]], value.history['loss'][0])\n",
    "  tf.keras.backend.clear_session()\n",
    "  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n",
    "  \n",
    "  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n",
    "  # histories = read_histories_from_csv(histories_save_path)\n",
    "  plot_history(histories, f'{output_folder}train_compression_rates/{pdfname}')\n",
    "  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n",
    "\n",
    "  testPerformance = evaluateTestSongs(autoencoder, num = 10)\n",
    "\n",
    "  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for row in testPerformance:\n",
    "        writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
