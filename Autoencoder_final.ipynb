{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 22:08:14.985610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import import_ipynb\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense,Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import uncertainties as unc\n",
    "import uncertainties.umath as umath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# utility functions\n",
    "# def cut_old(arr, length):\n",
    "#   idx = len(arr)%length\n",
    "#   out = []\n",
    "#   while(idx+length <= len(arr)):\n",
    "#     out.append(arr[idx:idx+length])\n",
    "#     idx += length\n",
    "#   return np.array(out)\n",
    "\n",
    "def cut(arr, length):\n",
    "  ueberhang = len(arr) % length\n",
    "  a = np.array(arr[ueberhang:]).reshape(-1, length)\n",
    "  return a\n",
    "\n",
    "# def loadSong(fName, numTotalSongs = 1):\n",
    "#   fs, data = wavfile.read(inpathTrain + fName)\n",
    "#   all_data = [data]\n",
    "\n",
    "#   if numTotalSongs > 1:\n",
    "#     seed = sum([ord(char) for char in fName])\n",
    "#     random.seed(seed)\n",
    "#     file_nams = random.sample(fileNames[:170], numTotalSongs-1)\n",
    "#     for name in file_nams:\n",
    "#       fs, data1 = wavfile.read(inpathTrain + name)\n",
    "#       all_data.append(data1)\n",
    "\n",
    "#   concatenated_data = np.concatenate(all_data)\n",
    "#   if concatenated_data.ndim > 1:\n",
    "#     mono_data = np.mean(concatenated_data, axis=1, dtype='int16')\n",
    "#   else:\n",
    "#     mono_data = concatenated_data\n",
    "\n",
    "#   return mono_data.astype('int16')\n",
    "\n",
    "def loadSong(fName, numTotalSongs = 1, percentage_of_song = 1):\n",
    "  fs, data = wavfile.read(inpathTrain + fName)\n",
    "\n",
    "  if numTotalSongs > 1:\n",
    "      # so that every song evey time picts the same songs for the additionals\n",
    "      seed = sum(ord(char) for char in fName)\n",
    "      random.seed(seed)\n",
    "      file_nams = random.sample(fileNames[:170], numTotalSongs - 1)\n",
    "      for name in file_nams:\n",
    "          fs, data1 = wavfile.read(inpathTrain + name)\n",
    "          data = np.concatenate((data, data1), axis=0)\n",
    "  \n",
    "  if data.ndim > 1:\n",
    "    mono_data = np.mean(data, axis=1, dtype='int16')\n",
    "  else:\n",
    "    mono_data = data\n",
    "\n",
    "  return mono_data.astype('int16')\n",
    "\n",
    "\n",
    "\n",
    "def loadSongCut(fName, silence_prob = 0, numTotalSongs = 1, percentage_of_song = 1):\n",
    "  data = loadSong(fName, numTotalSongs, percentage_of_song)\n",
    "  data = cut(data, snippitLength)\n",
    "\n",
    "  # Replace rows with silence based on silence_prob\n",
    "  if silence_prob!=0:\n",
    "    num_rows = data.shape[0]\n",
    "    num_silence_rows = int(num_rows * silence_prob)\n",
    "    silence_rows = np.zeros((num_silence_rows, data.shape[1]), dtype='int16')\n",
    "    data[:num_silence_rows, :] = silence_rows\n",
    "\n",
    "  scaler[fName] = MinMaxScaler()\n",
    "  #data = quadratic_scaler(data, 5)\n",
    "  data = scaler[fName].fit_transform(data)\n",
    "\n",
    "\n",
    "  # takes very long\n",
    "  # rng = np.random.default_rng()\n",
    "  # rng.shuffle(data)\n",
    "  # if percentage_of_song != 1:\n",
    "  #   index = int(data.shape[0]*percentage_of_song)\n",
    "  #   data = data[:index]\n",
    "  Xt, Xv = train_test_split(data, test_size=0.3, random_state=42)\n",
    "  if percentage_of_song != 1:\n",
    "    index_t = int(len(Xt)*percentage_of_song)\n",
    "    index_v = int(len(Xv)*percentage_of_song)\n",
    "    Xt = Xt[:index_t]\n",
    "    Xv = Xv[:index_v]\n",
    "  return Xt, Xv\n",
    "\n",
    "\n",
    "\n",
    "def snipLoss(y_true, y_pred):\n",
    "  snipWeight = tf.convert_to_tensor([int(np.cosh(x)) for x in range(-5, 5, snippitLength)], dtype='float32')\n",
    "  squared_difference = math_ops.squared_difference(y_true, y_pred)\n",
    "  loss = math_ops.Mul(x = squared_difference, y = snipWeight)\n",
    "  loss = math_ops.log1p(loss)\n",
    "  return loss\n",
    "\n",
    "\n",
    "\n",
    "def si_snr(original, estimate):\n",
    "  # original and estimate are tensors of shape (batch_size, time_steps)\n",
    "  # compute the dot product of original and estimate along the time axis\n",
    "  dot = tf.reduce_sum(original * estimate, axis=-1, keepdims=True)\n",
    "  denominator = tf.reduce_sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * tf.math.log(tf.reduce_sum(scaled_target ** 2, axis=-1) / tf.reduce_sum(e_noise ** 2, axis=-1)) / tf.math.log(10.0)\n",
    "  # return the SI-SNR tensor of shape (batch_size,)\n",
    "  return si_snr\n",
    "\n",
    "\n",
    "\n",
    "def si_snr_std(original, estimate):\n",
    "  dot = np.sum(original * estimate, axis=-1, keepdims=True)\n",
    "  # compute the energy of target along the time axis\n",
    "  denominator = np.sum(original ** 2, axis=-1, keepdims=True)\n",
    "  # compute the scaled target\n",
    "  scaled_target = dot * original / denominator\n",
    "  # compute the noise\n",
    "  e_noise = estimate - scaled_target\n",
    "  # compute the SI-SNR in decibels\n",
    "  si_snr = 10 * np.log10(np.sum(scaled_target ** 2, axis=-1) / np.sum(e_noise ** 2, axis=-1))\n",
    "  # return the SI-SNR array of shape (batch_size,)\n",
    "  return si_snr\n",
    "\n",
    "\n",
    "\n",
    "def mean_with_error(arr):\n",
    "    arr_unc = unc.ufloat(np.mean(arr), np.std(arr, ddof=1) / np.sqrt(len(arr)))\n",
    "    return f\"{arr_unc.nominal_value:.2f} +- {arr_unc.std_dev:.2f}\"\n",
    "\n",
    "# numTotalSongs = 17\n",
    "# percentage_of_song = float(1/numTotalSongs)\n",
    "# Xt, Xv = loadSongCut(fileNames[0], numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  plot history\n",
    "\n",
    "def plot_loss(ax, network_history):\n",
    "    loss = np.concatenate([network_history[key].history['loss'] for key in network_history.keys()])\n",
    "    val_loss = np.concatenate([network_history[key].history['val_loss'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss')\n",
    "    ax.plot(loss, label='Training')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_si_snr(ax, network_history):\n",
    "    si_snr = np.concatenate([network_history[key].history['si_snr'] for key in network_history.keys()])\n",
    "    val_si_snr = np.concatenate([network_history[key].history['val_si_snr'] for key in network_history.keys()])\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('SI_SNR')\n",
    "    ax.set_title('SI-SNR')\n",
    "    ax.plot(si_snr, label='Training')\n",
    "    ax.plot(val_si_snr, label='Validation')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_history(network_history, name):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=False)\n",
    "\n",
    "    plot_loss(ax[0], network_history)\n",
    "    plot_si_snr(ax[1], network_history)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name)\n",
    "    # plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  buildModel (Hyperparameter grid search)\n",
    "\n",
    "def buildModel(compression_ratio = 0.5, numDense = 1, numConv = 8, numConvLayer = 0, loss_fct = snipLoss, use_bias = False, learning_rate = 0.001):\n",
    "  \n",
    "  latentSize = int(compression_ratio*snippitLength)\n",
    "\n",
    "  # keep tensorflow from allocating more memory as it currently needs\n",
    "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "  for i in physical_devices:\n",
    "      tf.config.experimental.set_memory_growth(i, True)\n",
    "  tf.device('/device:GPU:0')\n",
    "\n",
    "  input = Input(shape=(snippitLength,1))\n",
    "  x = input\n",
    "\n",
    "  # Convolutional part of encoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(2, padding = 'same')(x)\n",
    "\n",
    "  convShape = x.shape\n",
    "  # calculate flatten dimension\n",
    "  flsize = 1\n",
    "  for i in x.shape:\n",
    "    if(i != None):\n",
    "      flsize*= i\n",
    "  x = Flatten()(x)\n",
    "\n",
    "  # Dense part of encoder\n",
    "  denses = [int(i) for i in np.linspace(flsize, latentSize, numDense+1)]\n",
    "  print(denses)\n",
    "  print(flsize)\n",
    "  print(latentSize)\n",
    "  for i in denses[1:]:\n",
    "    x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "    \n",
    "  encoded = x\n",
    "\n",
    "  # Dense part of decoder\n",
    "  x = encoded\n",
    "  for i in denses[::-1][1:]:\n",
    "    if(numConvLayer == 0 and i == snippitLength):\n",
    "      x = Dense(i, activation='sigmoid')(x)\n",
    "    else:\n",
    "      x = Dense(i, activation='relu', use_bias=use_bias)(x)\n",
    "\n",
    "  if(numConvLayer == 0):\n",
    "    decoded = x\n",
    "\n",
    "  x = Reshape(convShape[1:])(x)\n",
    "\n",
    "  # Convolutional part of decoder\n",
    "  for i in range(numConvLayer):\n",
    "    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n",
    "    x = UpSampling1D(2)(x)\n",
    "  if(numConvLayer != 0):\n",
    "    decoded = Conv1D(1, 5, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "  autoencoder = Model(input, decoded)\n",
    "  autoencoder = Model(input, Flatten()(decoded))\n",
    "\n",
    "  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fct, metrics=[si_snr])\n",
    "  \n",
    "  print(f'current model: ratio={compression_ratio},numDense={numDense},numConv={numConv},numConvLayer={numConvLayer}')\n",
    "  autoencoder.summary()\n",
    "  return autoencoder\n",
    "\n",
    "get_custom_objects()['snipLoss'] = snipLoss\n",
    "get_custom_objects()['si_snr'] = si_snr\n",
    "\n",
    "# testing:\n",
    "# Xt, Xv = loadSongCut('1727_schubert_op114_2.wav')\n",
    "# buildModel(numDense=1).fit(Xt[:2], Xt[:2],\n",
    "#             epochs=1,\n",
    "#             batch_size=512,\n",
    "#             shuffle=True,\n",
    "\n",
    "#             validation_data=(Xv[:2], Xv[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  evaluate Songs\n",
    "\n",
    "def evaluateTestSongs(autoencoder, num = 0):\n",
    "  test_evaluated = []\n",
    "  if num!=0:\n",
    "    numTestSongs = num\n",
    "  print(f'evaluating {numTestSongs} test songs')\n",
    "  for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n",
    "      orig = loadSong(songname)\n",
    "      origSnip = cut(orig, snippitLength)\n",
    "      orig = np.concatenate(origSnip)\n",
    "      \n",
    "      if(songname in scaler.keys()):\n",
    "        scaler_Example = scaler[songname]\n",
    "        origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "      else:\n",
    "        scaler_Example = MinMaxScaler()\n",
    "        origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "      # autoencode song\n",
    "      a = autoencoder.predict(origSnip_transformed)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      XpredSnip = scaler_Example.inverse_transform(a)\n",
    "      estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "\n",
    "      silence = np.zeros((1,snippitLength), dtype = 'int16')\n",
    "      a = scaler_Example.transform(silence)\n",
    "      a = autoencoder.predict(a)\n",
    "      a = a.reshape(-1, snippitLength)\n",
    "      Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "      # remove noise generated by silence\n",
    "      XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "      Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "\n",
    "      test_loss, test_si_snr_uncorr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed, verbose=2)\n",
    "      \n",
    "      test_si_snr_corrected = si_snr_std(orig, Xpred)\n",
    "      output_wav_name = f'{songname}_SNR={test_si_snr_corrected:.1f}.wav'\n",
    "      wavfile.write(f'{output_folder}original_{songname}', samplerate, orig)\n",
    "      wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "      print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "      test_evaluated.append([songname, test_loss, test_si_snr_uncorr, test_si_snr_corrected])\n",
    "  return test_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  waveform plots\n",
    "#####  predict test song and save it\n",
    "\n",
    "def plotWave(autoencoder, name, compression_ratio, Test_Song = None):\n",
    "  if Test_Song == None:\n",
    "    Test_Song = '1760_d958-4.wav'\n",
    "    # Test_Song = fileNames[-1]\n",
    "  # exampleSong = name\n",
    "  # exampleSong = '1727_schubert_op114_2.wav'\n",
    "  orig = loadSong(Test_Song)\n",
    "  origSnip = cut(orig, snippitLength)\n",
    "  orig = np.concatenate(origSnip)\n",
    "\n",
    "  if(Test_Song in scaler.keys()):\n",
    "    scaler_Example = scaler[Test_Song]\n",
    "    origSnip_transformed = scaler_Example.transform(origSnip)\n",
    "  else:\n",
    "    scaler_Example = MinMaxScaler()\n",
    "    origSnip_transformed = scaler_Example.fit_transform(origSnip)\n",
    "\n",
    "  # autoencode song\n",
    "  a = autoencoder.predict(origSnip_transformed)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  XpredSnip = scaler_Example.inverse_transform(a)\n",
    "  estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n",
    "\n",
    "  silence = np.zeros((1, snippitLength), dtype = 'int16')\n",
    "  a = scaler_Example.transform(silence)\n",
    "  a = autoencoder.predict(a)\n",
    "  a = a.reshape(-1, snippitLength)\n",
    "  Xsilence = scaler_Example.inverse_transform(a)[0]\n",
    "\n",
    "  # remove noise generated by silence\n",
    "  # XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n",
    "  XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n",
    "  Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n",
    "  estimate_corr = Xpred\n",
    "\n",
    "  # test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed)\n",
    "  si_snr_uncorr = si_snr_std(orig, estimate_uncorr)\n",
    "  print(f'ucorrected SI-SNR = {si_snr_uncorr} dB')\n",
    "\n",
    "  si_snr_corr = si_snr_std(orig, estimate_corr)\n",
    "  print(f'corrected SI-SNR = {si_snr_corr} dB')\n",
    "\n",
    "\n",
    "  # output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n",
    "  output_wav_name = f'{Test_Song}_{compression_ratio:.1f}_SNR={si_snr_corr:.1f}.wav'\n",
    "  wavfile.write(f'{output_folder}original_{Test_Song}', samplerate, orig)\n",
    "  wavfile.write(f'{output_folder}UNCORR_{output_wav_name}', samplerate, Xpred)\n",
    "  wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n",
    "  print(f\"Test song predicted and saved: {output_wav_name}\")\n",
    "\n",
    "\n",
    "  ###### plots\n",
    "  plt.plot(orig, linewidth = 0.1)\n",
    "  plt.plot(orig-estimate_corr, linewidth = 0.1)\n",
    "  plt.savefig(name + \"whole_corr.pdf\")\n",
    "  plt.clf()\n",
    "  plt.plot(orig, linewidth = 0.1)\n",
    "  plt.plot(orig-estimate_uncorr, linewidth = 0.1)\n",
    "  plt.savefig(name + \"whole_uncorr.pdf\")\n",
    "  plt.clf()\n",
    "  ####################################\n",
    "  #####  see difference in waveform detailed\n",
    "  nrows = 2\n",
    "  ncols = 6\n",
    "  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n",
    "  nrows = 2\n",
    "  ncols = 2\n",
    "  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_corrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n",
    "  s = 0\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n",
    "      ax[i][j].plot(XpredSnip[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      # ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n",
    "      s +=1\n",
    "  plt.savefig(name + \"snip_notcorrected.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "# model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "# plotWave(autoencoder, f'{output_folder}train_compression_rates/model_0.2_1_96_3wave_', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_histories_from_csv(file_path):\n",
    "    histories = {}\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            filename = row[0]\n",
    "            loss = float(row[1])\n",
    "            val_loss = float(row[2])\n",
    "            histories[filename] = {'loss': [loss], 'val_loss': [val_loss]}\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# drive.mount('/content/drive')\n",
    "# inpathTrain = \"/content/drive/MyDrive/Machine Learning/Autoencoder/train_data/\"\n",
    "# inpathOut = \"/content/drive/MyDrive/Machine Learning/Autoencoder/output/\"\n",
    "inpathTrain = \"songs/wav/\"\n",
    "output_folder = \"output/Versuch_new/\"\n",
    "fileNames = os.listdir(inpathTrain)\n",
    "random.seed(42)\n",
    "fileNames = random.sample(fileNames, len(fileNames))\n",
    "\n",
    "hyperparamsearch_folder = output_folder + 'hyperparamsearch'\n",
    "train_compression_rates_folder = output_folder + 'train_compression_rates'\n",
    "\n",
    "if not os.path.exists(hyperparamsearch_folder):\n",
    "    os.mkdir(hyperparamsearch_folder)\n",
    "\n",
    "if not os.path.exists(train_compression_rates_folder):\n",
    "    os.mkdir(train_compression_rates_folder)\n",
    "\n",
    "scaler = {}\n",
    "\n",
    "# global variables\n",
    "samplerate = 44_100\n",
    "snippitLength = 64\n",
    "\n",
    "loss_fct = snipLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1\n",
    "param_space = {'compression_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "               'numDense' : [1, 2, 3],\n",
    "               'numConv' : [8, 16],\n",
    "               'numConvLayer' : [0, 1, 2]}\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : np.linspace(0.1,0.9,2),\n",
    "#                'numDense' : [2, 3],\n",
    "#                'numConv' : [8, 6],\n",
    "#                'numConvLayer' : np.linspace(0.1,0.2,2)} # small 1\n",
    "# param_space = {'compression_ratio' : [0.1, 0.2],\n",
    "#                'numDense' : [3,4],\n",
    "#                'numConv' : [4, 8],\n",
    "#                'numConvLayer' : [0, 1]} # small 2\n",
    "\n",
    "\n",
    "# run 2.1\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [4, 5, 6],\n",
    "               'numConv' : [8, 16, 24, 32],\n",
    "               'numConvLayer' : [0, 1, 2, 3, 4]}\n",
    "\n",
    "# param_space = {'compression_ratio' : [0.2],\n",
    "#                'numDense' : [2, 3, 4],\n",
    "#                'numConv' : [32, 64],  # 128 too much memory need\n",
    "#                'numConvLayer' : [1, 2]}\n",
    "\n",
    "# run 2.2\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [3, 4, 5],\n",
    "               'numConv' : [64, 128],  # 128 too much memory need\n",
    "               'numConvLayer' : [2]}\n",
    "\n",
    "# run 2.3\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [32, 64],  # 128 too much memory need\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : [0.2],\n",
    "#                'numDense' : [1],\n",
    "#                'numConv' : [64, 96, 128],\n",
    "#                'numConvLayer' : [4, 6]}\n",
    "\n",
    "\n",
    "# param_space = {'compression_ratio' : [0.2],\n",
    "#                'numDense' : [5, 6],\n",
    "#                'numConv' : [24, 32],\n",
    "#                'numConvLayer' : [ 3, 4]}\n",
    "\n",
    "# run 2.4\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [ [32, 40, 48, 56, 64, 80, 112, 160, 192, 256]],\n",
    "               'numConvLayer' : [24, 32]}\n",
    "\n",
    "# run 3\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [32, 64, 128, 224],\n",
    "               'numConvLayer' : [1, 2]}\n",
    "\n",
    "# run 4\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [96],\n",
    "               'numConvLayer' : [2, 3]}\n",
    "\n",
    "\n",
    "#### quick test #####\n",
    "param_space = {'compression_ratio' : [0.2],\n",
    "               'numDense' : [1],\n",
    "               'numConv' : [64, 96],\n",
    "               'numConvLayer' : [2]}\n",
    "\n",
    "\n",
    "\n",
    "value_combis = itertools.product(*[v for v in param_space.values()])\n",
    "param_combis = []\n",
    "for combi in value_combis:\n",
    "  param_combi = {key: value for key, value in zip(param_space.keys(), combi)}\n",
    "  if param_combi['numConvLayer'] == 0:\n",
    "    param_combi['numConv'] = 0\n",
    "  param_combis.append(param_combi)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# real values\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "# numHyperTrainSongs = 170\n",
    "numHyperTrainSongs = 50\n",
    "\n",
    "# test values\n",
    "numTotalSongs = 2\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "numHyperEpochs = 2\n",
    "numHyperTrainSongs = 2\n",
    "\n",
    "# param_combis = param_combis[5:]\n",
    "time_per_combi = 2.6\n",
    "print(f'estimated time = {time_per_combi*len(param_combis)/60:.1f} h ({len(param_combis)} sets)')\n",
    "# param_combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#####  Hyperparameter grid search\n",
    "import stopwatch as sw\n",
    "\n",
    "t = sw.stopwatch(title='gridsearch', time_unit='s')\n",
    "\n",
    "# Load existing results from the JSON file if it exists\n",
    "existing_results = []\n",
    "existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_new.json'\n",
    "if os.path.exists(existing_file_path):\n",
    "    with open(existing_file_path, 'r') as file:\n",
    "        existing_results = json.load(file)\n",
    "\n",
    "search_results = []\n",
    "model_save_path = output_folder + 'hyperparamsearch/' + f'model.keras'\n",
    "if os.path.exists(model_save_path):\n",
    "    os.remove(model_save_path)\n",
    "\n",
    "for hyperParamSet in tqdm(param_combis):\n",
    "  autoencoder = buildModel(hyperParamSet['compression_ratio'],\n",
    "                           hyperParamSet['numDense'],\n",
    "                           hyperParamSet['numConv'],\n",
    "                           hyperParamSet['numConvLayer'])\n",
    "\n",
    "  histories = {}\n",
    "  t.task('hyperparam')\n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[:numHyperTrainSongs])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numHyperEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv))\n",
    "    del Xt\n",
    "    del Xv\n",
    "    if (idx % int(5/numHyperEpochs) == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "  t.stop()\n",
    "  del autoencoder\n",
    "  tf.keras.backend.clear_session()\n",
    "\n",
    "  pdfname = f'HyperParOpt, compression_ratio= {hyperParamSet[\"compression_ratio\"]:.1f}, numDense= {hyperParamSet[\"numDense\"]}, numConvLayer= {hyperParamSet[\"numConvLayer\"]}, numConv= {hyperParamSet[\"numConv\"]}.pdf'\n",
    "  plot_history(histories, output_folder + 'hyperparamsearch/' + pdfname)\n",
    "\n",
    "  loss = []\n",
    "  val_loss = []\n",
    "  train_si_snr = []\n",
    "  val_si_snr = []\n",
    "  for key in histories.keys():\n",
    "    loss.append(histories[key].history['loss'])\n",
    "    val_loss.append(histories[key].history['val_loss'])\n",
    "    train_si_snr.append(histories[key].history['si_snr'])\n",
    "    val_si_snr.append(histories[key].history['val_si_snr'])\n",
    "  loss         = np.concatenate(loss)\n",
    "  val_loss     = np.concatenate(val_loss)\n",
    "  train_si_snr = np.concatenate(train_si_snr)\n",
    "  val_si_snr   = np.concatenate(val_si_snr)\n",
    "\n",
    "  best_val_epoch    = np.argmax(val_si_snr)\n",
    "  best_val_si_snr   = np.max(val_si_snr)\n",
    "  best_val_loss     = np.min(val_loss)\n",
    "  best_train_si_snr = np.max(train_si_snr)\n",
    "  best_train_loss   = np.min(loss)\n",
    "\n",
    "  search_results.append({\n",
    "    **hyperParamSet,\n",
    "    'best_val_epoch': best_val_epoch,\n",
    "    'best_val_si_snr': best_val_si_snr,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_train_si_snr': best_train_si_snr,\n",
    "    'best_train_loss': best_train_loss\n",
    "  })\n",
    "\n",
    "\n",
    "  latest_results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n",
    "\n",
    "  # Merge existing results and latest results\n",
    "  all_results = existing_results + latest_results\n",
    "\n",
    "  # Write all results to the JSON file\n",
    "  with open(existing_file_path, 'w') as file:\n",
    "      json.dump(all_results, file, indent='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best model\n",
    "\n",
    "parSet_sum = {}\n",
    "for item in search_results:\n",
    "    numDense = item['numDense']\n",
    "    numConv = item['numConv']\n",
    "    numConvLayer = item['numConvLayer']\n",
    "    best_val_si_snr = item['best_val_si_snr']\n",
    "\n",
    "    key = (numDense, numConv, numConvLayer)\n",
    "    if key in parSet_sum:\n",
    "       parSet_sum[key] += best_val_si_snr\n",
    "    else:\n",
    "        parSet_sum[key] = best_val_si_snr\n",
    "\n",
    "keys = [k for k in parSet_sum.keys()]\n",
    "si_snr_sum = [parSet_sum[k] for k in keys]\n",
    "bestParSet = keys[np.argmax(si_snr_sum)]\n",
    "print(f'best set : {bestParSet}')\n",
    "\n",
    "\n",
    "# search_results_json = output_folder + 'hyperparamsearch/' + 'searchResults.json'\n",
    "# search_results_json = 'output/Versuch1_11.07.2023/searchResults.json'\n",
    "# search_results_json = 'output/Versuch3_13.07.2023/hyperparamsearch/searchResults_170songs_5epochs_final.json'\n",
    "# with open(search_results_json, 'r') as file:\n",
    "#     search_results = json.load(file)\n",
    "\n",
    "# compression_rates = np.linspace(0.1,0.9,9)\n",
    "compression_rates = [0.2]\n",
    "# silence_prob = 0.01\n",
    "\n",
    "\n",
    "numTestSongs = int(total_num_songs*0.3)\n",
    "numTopoEpochs = 1\n",
    "numTotalSongs = 17\n",
    "percentage_of_song = float(1/(numTotalSongs))\n",
    "total_num_songs = len(fileNames)\n",
    "numTopoTrainSongs = int(((total_num_songs*0.7)+1))  # 170\n",
    "numTopoTrainSongs = 50\n",
    "\n",
    "# test values\n",
    "numTopoTrainSongs = 2\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.00008\n",
    "\n",
    "model_save_path = output_folder + 'train_compression_rates/' + f'model_train_test.keras' #100\n",
    "histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train_test.csv'\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  return learning_rate\n",
    "# autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "for c in compression_rates:\n",
    "  # autoencoder = buildModel(c, bestParSet[0],bestParSet[1],bestParSet[2], learning_rate = learning_rate)\n",
    "  autoencoder = buildModel(c, 1, 96, 3, learning_rate = learning_rate)\n",
    "  # autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "  histories = {}\n",
    " \n",
    "  for idx, filename_train in tqdm(enumerate(fileNames[0:numTopoTrainSongs:])):\n",
    "    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n",
    "    histories[filename_train] = autoencoder.fit(Xt, Xt,\n",
    "                epochs=numTopoEpochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(Xv, Xv),\n",
    "                callbacks=[lr_scheduler])\n",
    "    del Xt\n",
    "    del Xv\n",
    "    save_period = int(9/numHyperEpochs)\n",
    "    save_period = 1\n",
    "    if (idx % save_period == 0) and (idx != 0):\n",
    "      autoencoder.save(model_save_path)\n",
    "      del autoencoder\n",
    "      autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "      # with open(histories_save_path, 'w', newline='') as csvfile:\n",
    "      #     writer = csv.writer(csvfile)\n",
    "      #     writer.writerow(['filename', 'loss', 'val_loss'])\n",
    "      #     for key, value in histories.items():\n",
    "      #         writer.writerow([key, value.history['loss'][0], value.history['val_loss'][0]], value.history['loss'][0])\n",
    "  tf.keras.backend.clear_session()\n",
    "  autoencoder.save(f'{output_folder}train_compression_rates/model_final_test.keras')\n",
    "  \n",
    "  pdfname = f'BestSet, compression_ratio ={c:.1f}_test.pdf'\n",
    "  # histories = read_histories_from_csv(histories_save_path)\n",
    "  plot_history(histories, f'{output_folder}train_compression_rates/{pdfname}')\n",
    "  plotWave(autoencoder, f'{output_folder}train_compression_rates/model_final_testwave_', c)\n",
    "\n",
    "  testPerformance = evaluateTestSongs(autoencoder, num = numTestSongs)\n",
    "\n",
    "  a = np.array(testPerformance)\n",
    "  snippets_si_snr = a[:,2].astype('float')\n",
    "  full_si_snr_corr = a[:,3].astype('float')\n",
    "\n",
    "\n",
    "\n",
    "  print(f'snippet_sni_snr {mean_with_error(snippets_si_snr)}')\n",
    "  print(f'full_si_snr_corr {mean_with_error(full_si_snr_corr)}')\n",
    "\n",
    "  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for row in testPerformance:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13327/13327 [==============================] - 52s 4ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ucorrected SI-SNR = -22.427609905205685 dB\n",
      "corrected SI-SNR = 15.169060838413325 dB\n",
      "Test song predicted and saved: 1760_d958-4.wav_0.2_SNR=15.2.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_folder = \"output/Versuch3_13.07.2023/\"\n",
    "model_save_path = f'{output_folder}train_compression_rates/modelCompressionRate0.2.keras' #100\n",
    "autoencoder = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "c = 0.2\n",
    "plotWave(autoencoder, f'{output_folder}', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 30 test songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9173/9173 [==============================] - 34s 4ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "9173/9173 - 36s - loss: 0.0139 - si_snr: 32.2439 - 36s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:16, 76.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1751_sy_sps13.wav_SNR=13.7.wav\n",
      "3645/3645 [==============================] - 12s 3ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "3645/3645 - 14s - loss: 0.0164 - si_snr: 31.3227 - 14s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:45, 48.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2442_ps29_02.wav_SNR=13.0.wav\n",
      "5465/5465 [==============================] - 19s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "5465/5465 - 23s - loss: 0.0132 - si_snr: 32.3413 - 23s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:30, 46.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2529_ps05_03.wav_SNR=14.4.wav\n",
      "14006/14006 [==============================] - 49s 3ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "14006/14006 - 54s - loss: 0.0091 - si_snr: 34.5042 - 54s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:21, 72.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2377_qt08_2.wav_SNR=14.0.wav\n",
      "5982/5982 [==============================] - 21s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "5982/5982 - 23s - loss: 0.0166 - si_snr: 31.6003 - 23s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [05:10, 63.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2373_ps19_01.wav_SNR=12.3.wav\n",
      "10837/10837 [==============================] - 38s 4ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "10837/10837 - 42s - loss: 0.0116 - si_snr: 33.2438 - 42s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [06:37, 71.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2570_bevs7a.wav_SNR=14.3.wav\n",
      "17906/17906 [==============================] - 66s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "17906/17906 - 71s - loss: 0.0098 - si_snr: 34.2575 - 71s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [09:09, 97.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2398_op47_2.wav_SNR=12.2.wav\n",
      "8322/8322 [==============================] - 30s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "8322/8322 - 32s - loss: 0.0121 - si_snr: 32.4951 - 32s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [10:17, 88.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2431_qt16_1.wav_SNR=15.3.wav\n",
      "8048/8048 [==============================] - 28s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "8048/8048 - 32s - loss: 0.0132 - si_snr: 32.8980 - 32s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [11:23, 81.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2492_ps04_04.wav_SNR=10.9.wav\n",
      "9120/9120 [==============================] - 31s 3ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "9120/9120 - 36s - loss: 0.0121 - si_snr: 32.9487 - 36s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [12:36, 78.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2345_ps14_03.wav_SNR=13.6.wav\n",
      "10679/10679 [==============================] - 40s 4ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "10679/10679 - 41s - loss: 0.0071 - si_snr: 35.4399 - 41s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [14:07, 82.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2607_ps16_02.wav_SNR=18.2.wav\n",
      "6636/6636 [==============================] - 24s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "6636/6636 - 27s - loss: 0.0116 - si_snr: 33.2445 - 27s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [15:02, 74.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2481_qt05_2.wav_SNR=16.2.wav\n",
      "9928/9928 [==============================] - 35s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "9928/9928 - 39s - loss: 0.0097 - si_snr: 34.2351 - 39s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [16:23, 76.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2568_ps27_02.wav_SNR=10.2.wav\n",
      "12125/12125 [==============================] - 43s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "12125/12125 - 48s - loss: 0.0206 - si_snr: 30.6818 - 48s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [18:03, 83.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1739_sb99m4.wav_SNR=2.8.wav\n",
      "3916/3916 [==============================] - 14s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "3916/3916 - 15s - loss: 0.0144 - si_snr: 32.2266 - 15s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [18:34, 67.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2384_qt13_4.wav_SNR=10.6.wav\n",
      "20904/20904 [==============================] - 73s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "20904/20904 - 79s - loss: 0.0069 - si_snr: 35.9108 - 79s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [21:22, 97.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2366_qt12_2.wav_SNR=16.2.wav\n",
      "7745/7745 [==============================] - 26s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "7745/7745 - 30s - loss: 0.0173 - si_snr: 31.9035 - 30s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [22:24, 87.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2404_ps31_01.wav_SNR=8.2.wav\n",
      "7274/7274 [==============================] - 26s 4ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "7274/7274 - 30s - loss: 0.0169 - si_snr: 31.3698 - 30s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [23:26, 79.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2478_ps03_04.wav_SNR=12.3.wav\n",
      "2878/2878 [==============================] - 11s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2878/2878 - 11s - loss: 0.0115 - si_snr: 33.5850 - 11s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [23:50, 62.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2620_ps06_03.wav_SNR=9.9.wav\n",
      "14858/14858 [==============================] - 52s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "14858/14858 - 59s - loss: 0.0113 - si_snr: 33.6252 - 59s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [25:53, 80.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1735_sy_sps94.wav_SNR=12.5.wav\n",
      "10340/10340 [==============================] - 38s 4ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "10340/10340 - 43s - loss: 0.0074 - si_snr: 35.1034 - 43s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [27:22, 83.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2593_ps18_01.wav_SNR=13.0.wav\n",
      "7274/7274 [==============================] - 26s 4ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "7274/7274 - 30s - loss: 0.0162 - si_snr: 31.2561 - 30s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [28:22, 76.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2473_ps03_04.wav_SNR=12.6.wav\n",
      "8979/8979 [==============================] - 35s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "8979/8979 - 38s - loss: 0.0178 - si_snr: 31.4011 - 38s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [29:41, 77.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1733_sy_sps92.wav_SNR=15.6.wav\n",
      "15835/15835 [==============================] - 56s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "15835/15835 - 62s - loss: 0.0158 - si_snr: 31.5875 - 62s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [31:51, 93.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1742_sb163m2.wav_SNR=18.7.wav\n",
      "7913/7913 [==============================] - 27s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "7913/7913 - 31s - loss: 0.0129 - si_snr: 32.5810 - 31s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [32:56, 84.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2586_vcs4_2.wav_SNR=16.1.wav\n",
      "8190/8190 [==============================] - 31s 4ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "8190/8190 - 35s - loss: 0.0092 - si_snr: 34.0586 - 35s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [34:07, 80.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 1790_kv_465_3.wav_SNR=18.6.wav\n",
      "4062/4062 [==============================] - 14s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "4062/4062 - 17s - loss: 0.0096 - si_snr: 34.0371 - 17s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [34:41, 66.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2619_ps06_02.wav_SNR=16.7.wav\n",
      "7842/7842 [==============================] - 28s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "7842/7842 - 30s - loss: 0.0155 - si_snr: 32.0384 - 30s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [35:45, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2603_ps26_01.wav_SNR=11.9.wav\n",
      "10168/10168 [==============================] - 35s 3ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "10168/10168 - 40s - loss: 0.0089 - si_snr: 34.5550 - 40s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [37:07, 70.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2393_ps17_03.wav_SNR=11.8.wav\n",
      "7992/7992 [==============================] - 27s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "7992/7992 - 28s - loss: 0.0155 - si_snr: 31.1238 - 28s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [38:07, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song predicted and saved: 2466_lvb23c.wav_SNR=17.9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(file)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m testPerformance:\n\u001b[0;32m----> 7\u001b[0m     writer\u001b[39m.\u001b[39;49mwriterow(row)\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "\n",
    "testPerformance = evaluateTestSongs(autoencoder, num = 30)\n",
    "\n",
    "with open(f'{output_folder}train_compression_rates/model_final_Performance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "for row in testPerformance:\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/martin/.local/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting uncertainties\n",
      "  Downloading uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting future (from uncertainties)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=9adb645a384177abe1f14adfdc0b34e2acadadd05f07bc28fc9740b9f244bcb0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kth3lnfu/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built future\n",
      "Installing collected packages: future, uncertainties\n",
      "Successfully installed future-0.18.3 uncertainties-3.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install uncertainties\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
