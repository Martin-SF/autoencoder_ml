{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1689112172443,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"syn0nt6E1bOO"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","# import tensorrt\n","#ImportError: Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.9.17 (main, Jul  5 2023, 20:41:20) \n","#[GCC 11.2.0].\n","# print(tf.__file__)\n","# import os\n","# print(os.environ['LD_LIBRARY_PATH'])\n","from tensorflow.keras.layers import Input, Dense,Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import get_custom_objects\n","from tensorflow.keras import backend as K\n","from tensorflow.python.ops import math_ops\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from tqdm import tqdm\n","from scipy.io import wavfile\n","import random\n","import itertools\n","import json\n","# from google.colab import drive"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: /home/martin/.local/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: import-ipynb in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (0.1.4)\n","Requirement already satisfied: IPython in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from import-ipynb) (8.14.0)\n","Requirement already satisfied: nbformat in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from import-ipynb) (5.9.1)\n","Requirement already satisfied: backcall in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: decorator in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.18.2)\n","Requirement already satisfied: matplotlib-inline in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.1.6)\n","Requirement already satisfied: pickleshare in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (3.0.39)\n","Requirement already satisfied: pygments>=2.4.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (2.15.1)\n","Requirement already satisfied: stack-data in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (5.9.0)\n","Requirement already satisfied: typing-extensions in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (4.5.0)\n","Requirement already satisfied: pexpect>4.3 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: fastjsonschema in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (2.17.1)\n","Requirement already satisfied: jsonschema>=2.6 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (4.18.3)\n","Requirement already satisfied: jupyter-core in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (5.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n","Requirement already satisfied: attrs>=22.2.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.6.1)\n","Requirement already satisfied: referencing>=0.28.4 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.29.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.8.10)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->import-ipynb) (0.2.6)\n","Requirement already satisfied: platformdirs>=2.5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jupyter-core->nbformat->import-ipynb) (3.8.1)\n","Requirement already satisfied: executing>=1.2.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (1.2.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (2.2.1)\n","Requirement already satisfied: pure-eval in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n","Requirement already satisfied: six in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->IPython->import-ipynb) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install import-ipynb"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1689112112219,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"GqBX39TFv-Rz"},"outputs":[],"source":["def cut(arr, length):\n","  idx = len(arr)%length\n","  out = []\n","  while(idx+length <= len(arr)):\n","    out.append(arr[idx:idx+length])\n","    idx += length\n","  return np.array(out)\n","\n","def loadSong(fName, numTotalSongs = 1):\n","  fs, data = wavfile.read(inpathTrain + fName)\n","  all_data = [data]\n","\n","  if numTotalSongs > 1:\n","    seed = sum([ord(char) for char in fName])\n","    random.seed(seed)\n","    file_nams = random.sample(fileNames[:170], numTotalSongs-1)\n","    for name in file_nams:\n","      fs, data1 = wavfile.read(inpathTrain + name)\n","      all_data.append(data1)\n","\n","  \n","  concatenated_data = np.concatenate(all_data)\n","  if concatenated_data.ndim > 1:\n","    mono_data = np.mean(concatenated_data, axis=1)\n","  else:\n","    mono_data = concatenated_data\n","\n","  # # all_data.append(data)\n","\n","  # # all_data = np.concatenate(data, data1)\n","  # for name in file_nams:\n","  #   fs, data1 = wavfile.read(inpathTrain + name)\n","  #   data = np.concatenate(data, data1)\n","  #   # all_data.append(data)\n","\n","  # all_data = np.array(data)\n","  # if data.ndim > 1:\n","  #   mono_data = np.mean(all_data, axis=1)\n","  # else:\n","  #   mono_data = all_data\n","\n","  return mono_data.astype('int16')\n","\n","def loadSongCut(fName, silence_prob = 0, numTotalSongs = 1, percentage_of_song = 1):\n","  data = loadSong(fName, numTotalSongs)\n","  data = cut(data, snippitLength)\n","\n","  # Replace rows with silence based on silence_prob\n","  if silence_prob!=0:\n","    num_rows = data.shape[0]\n","    num_silence_rows = int(num_rows * silence_prob)\n","    silence_rows = np.zeros((num_silence_rows, data.shape[1]))\n","    data[:num_silence_rows, :] = silence_rows\n","\n","\n","  scaler[fName] = MinMaxScaler()\n","  #data = quadratic_scaler(data, 5)\n","  data = scaler[fName].fit_transform(data)\n","\n","  Xt, Xv = train_test_split(data, test_size=0.3, random_state=42)\n","  if percentage_of_song != 1:\n","    index_t = int(len(Xt)*percentage_of_song)\n","    index_v = int(len(Xv)*percentage_of_song)\n","    Xt = Xt[:index_t]\n","    Xv = Xv[:index_v]\n","  return np.array(Xt), np.array(Xv)\n","\n","\n","\n","\n","def loadSongCut_tensor(fName, silence_prob = 0):\n","\n","  Xt, Xv = loadSongCut(fName, silence_prob)\n","\n","  # Convert NumPy arrays to TensorFlow tensors\n","  # Xt_tensor = tf.constant(Xt, dtype=tf.float32)\n","  # Xv_tensor = tf.constant(Xv, dtype=tf.float32)\n","  Xt_tensor = tf.constant(Xt, dtype=tf.int16)\n","  Xv_tensor = tf.constant(Xv, dtype=tf.int16)\n","\n","  # Create datasets from TensorFlow tensors\n","  dataset_Xt = tf.data.Dataset.from_tensor_slices(Xt_tensor)\n","  dataset_Xv = tf.data.Dataset.from_tensor_slices(Xv_tensor)\n","\n","  batch_size = 32  # Adjust according to memory availability and training efficiency\n","  buffer_size = 10000  # Set to a value larger than the dataset size but still fits in memory\n","  prefetch_size = 1  # Increase if input pipeline is a bottleneck, otherwise keep it low\n","\n","\n","  # Configure the datasets\n","  dataset_Xt = dataset_Xt.batch(batch_size)  # Set batch size\n","  dataset_Xt = dataset_Xt.shuffle(buffer_size=buffer_size)  # Enable shuffling\n","  dataset_Xt = dataset_Xt.prefetch(prefetch_size)  # Enable prefetching\n","\n","  dataset_Xv = dataset_Xv.batch(batch_size)  # Set batch size\n","  dataset_Xv = dataset_Xv.shuffle(buffer_size=buffer_size)  # Enable shuffling\n","  dataset_Xv = dataset_Xv.prefetch(prefetch_size)  # Enable prefetching\n","\n","  return dataset_Xt, dataset_Xv\n","\n","def digital_decibel(x):\n","  if (x>0):\n","    decibels = 1/ (10 * np.log10(x/1))\n","  else:\n","    decibels = 1 / (-1*  10 * np.log10(-x/1))\n","  return decibels\n","\n","def quadratic_scaler(x, n):\n","  v = [i**n for i in x]\n","  return v\n","\n","# s = loadSong('2633_ps10_03.wav', 2)\n","# wavfile.write('test.wav', 44100, s)\n","\n","# t, v = loadSongCut('2633_ps10_03.wav', numTotalSongs = 2, percentage_of_song = 0.1)\n","# t, v = loadSongCut('2633_ps10_03.wav') # ((93324, 64), (39996, 64))\n","# t, v = loadSongCut('2633_ps10_03.wav', numTotalSongs = 3, percentage_of_song = 0.3)\n","# t.shape, v.shape\n","# (45307, 64)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689112113489,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"KoAFMHZoABRx"},"outputs":[],"source":["def snipLoss(y_true, y_pred):\n","  snipWeight = tf.convert_to_tensor([int(np.cosh(x)) for x in range(-5, 5, snippitLength)], dtype='float32')\n","\n","  loss = math_ops.squared_difference(y_true,y_pred)\n","  loss = math_ops.Mul(x = loss,y = snipWeight)\n","  loss = math_ops.log1p(loss)\n","  return loss\n","\n","def si_snr2(y_true, y_pred):\n","  # Remove extra dimensions\n","  y_true = tf.squeeze(y_true)\n","  y_pred = tf.squeeze(y_pred)\n","\n","  # Compute the scaling factor\n","  scale = tf.reduce_sum(y_true * y_pred) / tf.reduce_sum(y_pred * y_pred)\n","\n","  # Compute the estimated source and the target source\n","  est_source = scale * y_pred\n","  target_source = y_true\n","\n","  # Compute the noise source\n","  noise_source = est_source - target_source\n","\n","  # Compute the SI-SNR\n","  numerator = tf.reduce_sum(target_source * est_source, axis=-1)\n","  denominator = tf.reduce_sum(noise_source * noise_source, axis=-1)\n","  si_snr = 10 * tf.math.log(numerator / denominator + 1e-8) / tf.math.log(10.0)\n","\n","  # Return the average SI-SNR\n","  return tf.reduce_mean(si_snr)\n","\n","def si_snr(original, estimate):\n","  # original and estimate are tensors of shape (batch_size, time_steps)\n","  # compute the dot product of original and estimate along the time axis\n","  dot = tf.reduce_sum(original * estimate, axis=-1, keepdims=True)\n","  denominator = tf.reduce_sum(original ** 2, axis=-1, keepdims=True)\n","  # compute the scaled target\n","  scaled_target = dot * original / denominator\n","  # compute the noise\n","  e_noise = estimate - scaled_target\n","  # compute the SI-SNR in decibels\n","  si_snr = 10 * tf.math.log(tf.reduce_sum(scaled_target ** 2, axis=-1) / tf.reduce_sum(e_noise ** 2, axis=-1)) / tf.math.log(10.0)\n","  # return the SI-SNR tensor of shape (batch_size,)\n","  return si_snr"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4029,"status":"ok","timestamp":1689112280618,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"YqamE_X1B0On","outputId":"1e058a44-8385-4e82-db5a-f15abc0c90ea"},"outputs":[],"source":["# paths\n","# drive.mount('/content/drive')\n","# inpathTrain = \"/content/drive/MyDrive/Machine Learning/Autoencoder/train_data/\"\n","# inpathOut = \"/content/drive/MyDrive/Machine Learning/Autoencoder/output/\"\n","inpathTrain = \"/mnt/e/data/SynologyDrive/Uni/mSem02/Machine Learning/Project_Audio_Autoencoder/musicnet_midis/BOT/Mixdown/output/\"\n","inpathOut =   \"/home/martin/martin_user_data/jupyter_notebooks/autoencoder_ml/output/\"\n","output_folder = \"output/Versuch3_13.07.2023/\"\n","fileNames = os.listdir(inpathTrain)\n","random.seed(42)\n","fileNames = random.sample(fileNames, len(fileNames))\n","\n","hyperparamsearch_folder = output_folder + 'hyperparamsearch'\n","train_compression_rates_folder = output_folder + 'train_compression_rates'\n","\n","if not os.path.exists(hyperparamsearch_folder):\n","    os.mkdir(hyperparamsearch_folder)\n","\n","if not os.path.exists(train_compression_rates_folder):\n","    os.mkdir(train_compression_rates_folder)\n","\n","scaler = {}\n","\n","# global variables\n","samplerate = 44_100\n","snippitLength = 64\n","\n","loss_fct = snipLoss\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1689112243940,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"7Cl3Ffyg7uxx"},"outputs":[],"source":["####################################\n","#####  plot history\n","\n","def plot_loss(ax, network_history):\n","    loss = np.concatenate([network_history[key].history['loss'] for key in network_history.keys()])\n","    val_loss = np.concatenate([network_history[key].history['val_loss'] for key in network_history.keys()])\n","\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel('Loss')\n","    ax.set_title('Loss')\n","    ax.plot(loss, label='Training')\n","    ax.plot(val_loss, label='Validation')\n","    ax.legend()\n","\n","def plot_si_snr(ax, network_history):\n","    si_snr = np.concatenate([network_history[key].history['si_snr'] for key in network_history.keys()])\n","    val_si_snr = np.concatenate([network_history[key].history['val_si_snr'] for key in network_history.keys()])\n","\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel('SI_SNR')\n","    ax.set_title('SI-SNR')\n","    ax.plot(si_snr, label='Training')\n","    ax.plot(val_si_snr, label='Validation')\n","    ax.legend()\n","\n","def plot_history(network_history, name):\n","    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=False)\n","\n","    plot_loss(ax[0], network_history)\n","    plot_si_snr(ax[1], network_history)\n","\n","    plt.tight_layout()\n","    plt.savefig(name)\n","    # plt.show()\n","    plt.clf()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1689112246220,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"v5Bv1lsxEPSL"},"outputs":[{"name":"stdout","output_type":"stream","text":["[64, 32]\n","64\n","32\n","current model: ratio=0.5,numDense=1,numConv=8,numConvLayer=0\n","Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 64, 1)]           0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 64)                0         \n","                                                                 \n"," dense_8 (Dense)             (None, 32)                2048      \n","                                                                 \n"," dense_9 (Dense)             (None, 64)                2112      \n","                                                                 \n"," flatten_9 (Flatten)         (None, 64)                0         \n","                                                                 \n","=================================================================\n","Total params: 4,160\n","Trainable params: 4,160\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f05ef6cedc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - ETA: 0s - loss: 0.4789 - si_snr: 13.8553WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f05c5399670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 1s 646ms/step - loss: 0.4789 - si_snr: 13.8553 - val_loss: 0.7178 - val_si_snr: 14.6991\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f05ef6d0f40>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["####################################\n","#####  buildModel (Hyperparameter grid search)\n","# tf.random.set_seed(42)\n","def lr_schedule(epoch):\n","  if epoch < 10:\n","      return 0.01\n","  else:\n","      return 0.001\n","\n","# def buildModel(compression_ratio = 0.5, numDense = 2, numConv = 8,numConvLayer = 2, loss_fct = snipLoss, use_bias = False):\n","def buildModel(compression_ratio = 0.5, numDense = 1, numConv = 8, numConvLayer = 0, loss_fct = snipLoss, use_bias = False, learning_rate = 0.001):\n","\n","\n","\n","  latentSize = int(compression_ratio*snippitLength)\n","\n","  # keep tensorflow from allocating more memory as it currently needs\n","  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","  for i in physical_devices:\n","      tf.config.experimental.set_memory_growth(i, True)\n","  tf.device('/device:GPU:0')\n","\n","  input = Input(shape=(snippitLength,1))\n","  x = input\n","\n","  # Convolutional part of encoder\n","  for i in range(numConvLayer):\n","    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n","    x = MaxPooling1D(2, padding = 'same')(x)\n","\n","  convShape = x.shape\n","  # calculate flatten dimension\n","  flsize = 1\n","  for i in x.shape:\n","    if(i != None):\n","      flsize*= i\n","\n","  # print(f'{latentSize} {flsize}')\n","  x = Flatten()(x)\n","\n","\n","  # Dense part of encoder\n","  denses = [int(i) for i in np.linspace(flsize, latentSize, numDense+1)]\n","  print(denses)\n","  print(flsize)\n","  print(latentSize)\n","  for i in denses[1:]:\n","    x = Dense(i, activation='relu', use_bias=use_bias)(x)\n","\n","  encoded = x\n","\n","  # for i in denses:\n","\n","  # Dense part of decoder\n","  x = encoded\n","  for i in denses[::-1][1:]:\n","    if(numConvLayer == 0 and i == snippitLength):\n","      x = Dense(i, activation='sigmoid')(x)\n","    else:\n","      x = Dense(i, activation='relu', use_bias=use_bias)(x)\n","\n","  if(numConvLayer == 0):\n","    decoded = x\n","\n","  x = Reshape(convShape[1:])(x)\n","\n","  # Convolutional part of decoder\n","  for i in range(numConvLayer):\n","    x = Conv1D(numConv,5, activation='relu', padding='same')(x)\n","    x = UpSampling1D(2)(x)\n","  if(numConvLayer != 0):\n","    decoded = Conv1D(1,5, activation='sigmoid', padding='same')(x)\n","\n","  autoencoder = Model(input, decoded)\n","  autoencoder = Model(input, Flatten()(decoded))\n","\n","  \n","  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fct, metrics=[si_snr])\n","  \n","  print(f'current model: ratio={compression_ratio},numDense={numDense},numConv={numConv},numConvLayer={numConvLayer}')\n","  autoencoder.summary()\n","  return autoencoder\n","\n","\n","\n","get_custom_objects()['snipLoss'] = snipLoss\n","get_custom_objects()['si_snr'] = si_snr\n","Xt, Xv = loadSongCut('1727_schubert_op114_2.wav')\n","buildModel(numDense=1).fit(Xt[:2], Xt[:2],\n","            epochs=1,\n","            batch_size=512,\n","            shuffle=True,\n","\n","            validation_data=(Xv[:2], Xv[:2]))"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["flsize = 64\n","latentSize = 32\n","numDense = 1\n","\n","denses = [int(i) for i in np.linspace(1, 10, 10)]\n","\n","# print(denses)\n","# for i in denses[::-1][1:]:\n","#     print(i)\n","# for i in denses[::-1]:\n","#     print(i)\n","denses[::-1]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1689112249189,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"EcSaNyxC66NZ","outputId":"1f75acec-4823-494a-d349-049550b31de8"},"outputs":[{"name":"stdout","output_type":"stream","text":["estimated time = 4.2 h (6 sets)\n"]},{"data":{"text/plain":["[{'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 6}]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["param_space = {'compression_ratio' : [0.1, 0.2, 0.3, 0.4],\n","               'numDense' : [3, 4, 5, 6],\n","               'numConv' : [8, 16],\n","               'numConvLayer' : [0, 1, 2]}\n","\n","\n","\n","# param_space = {'compression_ratio' : np.linspace(0.1,0.9,2),\n","#                'numDense' : [2, 3],\n","#                'numConv' : [8, 6],\n","#                'numConvLayer' : np.linspace(0.1,0.2,2)} # small 1\n","# param_space = {'compression_ratio' : [0.1, 0.2],\n","#                'numDense' : [3,4],\n","#                'numConv' : [4, 8],\n","#                'numConvLayer' : [0, 1]} # small 2\n","\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [2, 3, 4, 5, 6],\n","               'numConv' : [8, 16, 24, 32],\n","               'numConvLayer' : [0, 1, 2, 3, 4]}\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [2, 3, 4],\n","               'numConv' : [32, 64],  # 128 too much memory need\n","               'numConvLayer' : [1, 2]}\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [1],\n","               'numConv' : [32, 64],  # 128 too much memory need\n","               'numConvLayer' : [1, 2]}\n","\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [1],\n","               'numConv' : [64, 96, 128],\n","               'numConvLayer' : [4, 6]}\n","\n","\n","# param_space = {'compression_ratio' : [0.2],\n","#                'numDense' : [5, 6],\n","#                'numConv' : [24, 32],\n","#                'numConvLayer' : [ 3, 4]}\n","\n","numHyperTrainSongs = 120\n","numHyperTrainSongs = 170\n","numHyperTrainSongs = 70\n","numHyperEpochs = 1\n","# numHyperTrainSongs = 170\n","# numHyperEpochs = 10\n","\n","value_combis = itertools.product(*[v for v in param_space.values()])\n","param_combis = []\n","for combi in value_combis:\n","  param_combi = {key: value for key, value in zip(param_space.keys(), combi)}\n","  if param_combi['numConvLayer'] == 0:\n","    param_combi['numConv'] = 0\n","  param_combis.append(param_combi)\n","\n","# param_combis = [\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 2}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 3}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2}, # 48.5\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}, # 48.5\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 2}, # 49.6\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 3}] # 49.6\n","\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","# param_combis = [\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 4},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 5},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 6}]\n","\n","time_per_combi = 2.6\n","time_per_combi = 3*3.5*4\n","print(f'estimated time = {time_per_combi*len(param_combis)/60:.1f} h ({len(param_combis)} sets)')\n","# param_combis = param_combis[-1:]\n","# param_combis = reversed(param_combis)\n","param_combis = param_combis[5:]\n","param_combis"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Iu7RTlE668_-","slideshow":{"slide_type":"slide"}},"outputs":[],"source":["# ####################################\n","# #####  Hyperparameter grid search\n","# import stopwatch as sw\n","\n","# t = sw.stopwatch(title='gridsearch', time_unit='s')\n","\n","# # Load existing results from the JSON file if it exists\n","# existing_results = []\n","# existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_3epochs.json'\n","# existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_1epochs_final.json'\n","# if os.path.exists(existing_file_path):\n","#     with open(existing_file_path, 'r') as file:\n","#         existing_results = json.load(file)\n","\n","# random.seed(42)\n","# filename_random = random.sample(fileNames, 170)\n","# search_results = []\n","# model_save_path = output_folder + 'hyperparamsearch/' + f'model.keras'\n","# if os.path.exists(model_save_path):\n","#     os.remove(model_save_path)\n","\n","# for hyperParamSet in tqdm(param_combis):\n","#   autoencoder = buildModel(hyperParamSet['compression_ratio'],\n","#                            hyperParamSet['numDense'],\n","#                            hyperParamSet['numConv'],\n","#                            hyperParamSet['numConvLayer'])\n","\n","#   # autoencoder = buildModel()\n","#   histories = {}\n","#   # numHyperTrainSongs = 10\n","#   batch_size=4096\n","#   t.task('hyperparam')\n","#   for idx, filename_train in tqdm(enumerate(filename_random[:numHyperTrainSongs])):\n","#     Xt, Xv = loadSongCut(filename_train)\n","#     histories[filename_train] = autoencoder.fit(Xt, Xt,\n","#                 epochs=numHyperEpochs,\n","#                 batch_size=batch_size,\n","#                 shuffle=True,\n","#                 validation_data=(Xv, Xv))\n","#     del Xt\n","#     del Xv\n","#     if (idx % int(5/numHyperEpochs) == 0) and (idx != 0):\n","#       autoencoder.save(model_save_path)\n","#       del autoencoder\n","#       autoencoder = tf.keras.models.load_model(model_save_path)\n","#   t.stop()\n","#   del autoencoder\n","#   tf.keras.backend.clear_session()\n","\n","#   pdfname = f'HyperParOpt, compression_ratio= {hyperParamSet[\"compression_ratio\"]:.1f}, numDense= {hyperParamSet[\"numDense\"]}, numConvLayer= {hyperParamSet[\"numConvLayer\"]}, numConv= {hyperParamSet[\"numConv\"]}.pdf'\n","#   plot_history(histories, output_folder + 'hyperparamsearch/' + pdfname)\n","\n","#   loss = []\n","#   val_loss = []\n","#   train_si_snr = []\n","#   val_si_snr = []\n","#   for key in histories.keys():\n","#     loss.append(histories[key].history['loss'])\n","#     val_loss.append(histories[key].history['val_loss'])\n","#     train_si_snr.append(histories[key].history['si_snr'])\n","#     val_si_snr.append(histories[key].history['val_si_snr'])\n","#   loss         = np.concatenate(loss)\n","#   val_loss     = np.concatenate(val_loss)\n","#   train_si_snr = np.concatenate(train_si_snr)\n","#   val_si_snr   = np.concatenate(val_si_snr)\n","\n","#   best_val_epoch    = np.argmax(val_si_snr)\n","#   best_val_si_snr   = np.max(val_si_snr)\n","#   best_val_loss     = np.min(val_loss)\n","#   best_train_si_snr = np.max(train_si_snr)\n","#   best_train_loss   = np.min(loss)\n","\n","#   search_results.append({\n","#     **hyperParamSet,\n","#     'best_val_epoch': best_val_epoch,\n","#     'best_val_si_snr': best_val_si_snr,\n","#     'best_val_loss': best_val_loss,\n","#     'best_train_si_snr': best_train_si_snr,\n","#     'best_train_loss': best_train_loss\n","#   })\n","\n","\n","#   latest_results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n","\n","#   # Merge existing results and latest results\n","#   all_results = existing_results + latest_results\n","\n","#   # Write all results to the JSON file\n","#   with open(existing_file_path, 'w') as file:\n","#       json.dump(all_results, file, indent='')\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# # Merge existing results and latest results\n","# all_results = existing_results + latest_results\n","\n","# # Write all results to the JSON file\n","# with open(existing_file_path, 'w') as file:\n","#     json.dump(all_results, file, indent='')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"zRzwd5jJ7Gj-"},"outputs":[],"source":["# \n","\n","# results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n","\n","# with open(output_folder + 'hyperparamsearch/' + 'searchResults.json', 'w') as file:\n","#     json.dump(results, file, indent = '')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# import import_ipynb\n","# from plot_hyperparameter import *\n","# hyperparameter_Plot(results, output_folder)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"fe4Pbw928oVb"},"outputs":[],"source":["####################################\n","#####  evaluate test songs\n","\n","# numTestSongs = 2\n","# def evaluateTestSongs(autoencoder, num = 0):\n","#   index = 0\n","#   test_evaluated = []\n","#   if num!=0:\n","#     numTestSongs = num\n","#   print(f'evaluating {numTestSongs} test songs')\n","#   for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n","#       # songname = '1727_schubert_op114_2.wav'\n","#       song = loadSong(songname)\n","#       # wavfile.write(inpathOut + songname + '.wav', samplerate, song)\n","#       songSnip = cut(song, snippitLength)\n","\n","#       songSnip_transformed = MinMaxScaler().fit_transform(songSnip)\n","#       test_loss, test_si_snr = autoencoder.evaluate(songSnip_transformed, songSnip_transformed, verbose=2)\n","\n","#       test_evaluated.append([songname, test_loss, test_si_snr])\n","#   return test_evaluated\n","\n","\n","def evaluateTestSongs(autoencoder, num = 0):\n","  index = 0\n","  test_evaluated = []\n","  if num!=0:\n","    numTestSongs = num\n","  print(f'evaluating {numTestSongs} test songs')\n","  for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n","      # songname = '1727_schubert_op114_2.wav'\n","      orig = loadSong(songname)\n","      # wavfile.write(inpathOut + songname + '.wav', samplerate, song)\n","      origSnip = cut(orig, snippitLength)\n","      orig = np.concatenate(origSnip)\n","      \n","      if(songname in scaler.keys()):\n","        scaler_Example = scaler[songname]\n","        origSnip_transformed = scaler_Example.transform(origSnip)\n","      else:\n","        scaler_Example = MinMaxScaler()\n","        origSnip_transformed = scaler_Example.fit_transform(origSnip)\n","\n","      # autoencode song\n","      a = autoencoder.predict(origSnip_transformed)\n","      a = a.reshape(-1, snippitLength)\n","      XpredSnip = scaler_Example.inverse_transform(a)\n","\n","      silence = np.zeros((1,snippitLength), dtype = 'int16')\n","      a = scaler_Example.transform(silence)\n","      a = autoencoder.predict(a)\n","      a = a.reshape(-1, snippitLength)\n","      Xsilence = scaler_Example.inverse_transform(a)[0]\n","\n","      # remove noise generated by silence\n","      XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n","      Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n","\n","      test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed, verbose=2)\n","      test_si_snr_corrected = si_snr_std(orig, Xpred)\n","      output_wav_name = f'{songname}snln={snippitLength}_cmpr=0.2_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n","      # wavfile.write(output_folder + 'original.wav', samplerate, orig)\n","      wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n","      print(f\"file saved: {output_wav_name}\")\n","\n","      test_evaluated.append([songname, test_loss, test_si_snr, test_si_snr_corrected])\n","  return test_evaluated\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"_1XeEUQ-90bk"},"outputs":[],"source":["####################################\n","#####  predict unknown song\n","\n","def plotWave(autoencoder, name, compression_ratio):\n","  exampleSong = fileNames[-1]\n","  # exampleSong = '1727_schubert_op114_2.wav'\n","  orig = loadSong(exampleSong)\n","  origSnip = cut(orig, snippitLength)\n","  orig = np.concatenate(origSnip)\n","\n","  if(exampleSong in scaler.keys()):\n","    scaler_Example = scaler[exampleSong]\n","    origSnip_transformed = scaler_Example.transform(origSnip)\n","  else:\n","    scaler_Example = MinMaxScaler()\n","    origSnip_transformed = scaler_Example.fit_transform(origSnip)\n","\n","  # autoencode song\n","  a = autoencoder.predict(origSnip_transformed)\n","  a = a.reshape(-1, snippitLength)\n","  XpredSnip = scaler_Example.inverse_transform(a)\n","\n","  silence = np.zeros((1,snippitLength), dtype = 'int16')\n","  a = scaler_Example.transform(silence)\n","  a = autoencoder.predict(a)\n","  a = a.reshape(-1, snippitLength)\n","  Xsilence = scaler_Example.inverse_transform(a)[0]\n","\n","  # remove noise generated by silence\n","  # XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n","  XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n","  Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n","\n","  # test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed)\n","  testwav_si_snr = si_snr_std(orig, Xpred)\n","  output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n","  wavfile.write(output_folder + 'original.wav', samplerate, orig)\n","  wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n","  print(f\"file saved: {output_wav_name}\")\n","\n","  plt.plot(orig, linewidth = 0.1)\n","  plt.plot(orig-Xpred, linewidth = 0.1)\n","  plt.savefig(name + \"whole.pdf\")\n","  plt.clf()\n","  ####################################\n","  #####  see difference in waveform detailed\n","  nrows = 2\n","  ncols = 6\n","  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n","\n","  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n","  s = 0\n","  for i in range(nrows):\n","    for j in range(ncols):\n","      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n","      ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n","      s +=1\n","  plt.savefig(name + \"snip_corrected.pdf\")\n","  plt.clf()\n","\n","  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n","  s = 0\n","  for i in range(nrows):\n","    for j in range(ncols):\n","      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n","      ax[i][j].plot(XpredSnip[snips[s]], linewidth = 0.5, c = 'r')\n","      # ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n","      s +=1\n","  plt.savefig(name + \"snip_notcorrected.pdf\")\n","  plt.clf()\n","\n","\n","def si_snr_std(original, estimate):\n","  dot = np.sum(original * estimate, axis=-1, keepdims=True)\n","  # compute the energy of target along the time axis\n","  denominator = np.sum(original ** 2, axis=-1, keepdims=True)\n","  # compute the scaled target\n","  scaled_target = dot * original / denominator\n","  # compute the noise\n","  e_noise = estimate - scaled_target\n","  # compute the SI-SNR in decibels\n","  si_snr = 10 * np.log10(np.sum(scaled_target ** 2, axis=-1) / np.sum(e_noise ** 2, axis=-1))\n","  # return the SI-SNR array of shape (batch_size,)\n","  return si_snr\n","\n","# model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n","# autoencoder = tf.keras.models.load_model(model_save_path)\n","# plotWave(autoencoder, f'{output_folder}train_compression_rates/model_0.2_1_96_3wave_', 0.2)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2071/4890 [===========>..................] - ETA: 11s"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# autoencode song\u001b[39;00m\n\u001b[1;32m     16\u001b[0m autoencoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(model_save_path)\n\u001b[0;32m---> 17\u001b[0m a \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mpredict(origSnip_transformed)\n\u001b[1;32m     18\u001b[0m a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, snippitLength)\n\u001b[1;32m     19\u001b[0m XpredSnip \u001b[39m=\u001b[39m scaler_Example\u001b[39m.\u001b[39minverse_transform(a)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2381\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2383\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2384\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n","\n","exampleSong = fileNames[-1]\n","orig = loadSong(exampleSong)\n","origSnip = cut(orig, snippitLength)\n","orig = np.concatenate(origSnip)\n","\n","if(exampleSong in scaler.keys()):\n","  scaler_Example = scaler[exampleSong]\n","  origSnip_transformed = scaler_Example.transform(origSnip)\n","else:\n","  scaler_Example = MinMaxScaler()\n","  origSnip_transformed = scaler_Example.fit_transform(origSnip)\n","\n","# autoencode song\n","autoencoder = tf.keras.models.load_model(model_save_path)\n","a = autoencoder.predict(origSnip_transformed)\n","a = a.reshape(-1, snippitLength)\n","XpredSnip = scaler_Example.inverse_transform(a)\n","\n","silence = np.zeros((1,snippitLength), dtype = 'int16')\n","a = scaler_Example.transform(silence)\n","a = autoencoder.predict(a)\n","a = a.reshape(-1, snippitLength)\n","Xsilence = scaler_Example.inverse_transform(a)[0]\n","\n","# remove noise generated by silence\n","# XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n","XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n","Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ucorrected SI-SNR -4.526547700446205 dB\n","corrected SI-SNR 12.08536407144872 dB\n"]}],"source":["estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n","estimate_corr = Xpred\n","original = orig\n","\n","uncorr = si_snr_std(original, estimate_uncorr)\n","print(f'ucorrected SI-SNR {uncorr} dB')\n","\n","corr = si_snr_std(original, estimate_corr)\n","print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d2 = np.array(original) - 0.1\n","# corr = si_snr_std(original, original_d2)\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d2 = np.array(original) + 1\n","# corr = si_snr_std(original, original_d2)\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d = [i+0.01 for i in original]\n","# corr = si_snr_std(original, np.concatenate(original_d).astype('int16'))\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n","# wavfile.write(output_folder + 'original.wav', samplerate, orig)\n","# wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"_XQYjrwo7IcC"},"outputs":[{"name":"stdout","output_type":"stream","text":["current model: ratio=0.2,numDense=1,numConv=96,numConvLayer=3\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["2590/2590 [==============================] - 39s 13ms/step - loss: 0.0418 - si_snr: 34.9630 - val_loss: 0.0061 - val_si_snr: 40.3039 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:47, 47.28s/it]"]},{"name":"stdout","output_type":"stream","text":["3031/3031 [==============================] - 40s 13ms/step - loss: 0.0057 - si_snr: 40.5021 - val_loss: 0.0048 - val_si_snr: 41.8367 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["2it [01:38, 49.85s/it]"]},{"name":"stdout","output_type":"stream","text":["3419/3419 [==============================] - 47s 13ms/step - loss: 0.0037 - si_snr: 42.9366 - val_loss: 0.0029 - val_si_snr: 44.0715 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["3it [02:38, 54.18s/it]"]},{"name":"stdout","output_type":"stream","text":["2759/2759 [==============================] - 41s 14ms/step - loss: 0.0029 - si_snr: 43.3130 - val_loss: 0.0023 - val_si_snr: 44.6818 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["4it [03:26, 51.89s/it]"]},{"name":"stdout","output_type":"stream","text":["2841/2841 [==============================] - 42s 14ms/step - loss: 0.0027 - si_snr: 43.9690 - val_loss: 0.0021 - val_si_snr: 44.9022 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["5it [04:17, 51.47s/it]"]},{"name":"stdout","output_type":"stream","text":["2748/2748 [==============================] - 41s 14ms/step - loss: 0.0021 - si_snr: 45.0608 - val_loss: 0.0018 - val_si_snr: 45.1385 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["6it [05:05, 50.49s/it]"]},{"name":"stdout","output_type":"stream","text":["2692/2692 [==============================] - 40s 14ms/step - loss: 0.0021 - si_snr: 45.4667 - val_loss: 0.0016 - val_si_snr: 46.4774 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["7it [05:53, 49.43s/it]"]},{"name":"stdout","output_type":"stream","text":["2629/2629 [==============================] - 36s 13ms/step - loss: 0.0019 - si_snr: 46.0187 - val_loss: 0.0022 - val_si_snr: 46.6335 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["8it [06:35, 47.26s/it]"]},{"name":"stdout","output_type":"stream","text":["2684/2684 [==============================] - 41s 14ms/step - loss: 0.0022 - si_snr: 45.2407 - val_loss: 0.0018 - val_si_snr: 45.7542 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["9it [07:23, 47.39s/it]"]},{"name":"stdout","output_type":"stream","text":["2899/2899 [==============================] - 43s 14ms/step - loss: 0.0018 - si_snr: 46.2761 - val_loss: 0.0014 - val_si_snr: 46.6321 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["10it [08:12, 47.88s/it]"]},{"name":"stdout","output_type":"stream","text":["2805/2805 [==============================] - 39s 13ms/step - loss: 0.0016 - si_snr: 46.6942 - val_loss: 0.0015 - val_si_snr: 47.7946 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["11it [08:58, 47.20s/it]"]},{"name":"stdout","output_type":"stream","text":["2618/2618 [==============================] - 36s 13ms/step - loss: 0.0015 - si_snr: 46.7004 - val_loss: 0.0013 - val_si_snr: 47.0172 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["12it [09:39, 45.47s/it]"]},{"name":"stdout","output_type":"stream","text":["3288/3288 [==============================] - 44s 13ms/step - loss: 0.0015 - si_snr: 47.4446 - val_loss: 0.0014 - val_si_snr: 47.8449 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["13it [10:34, 48.30s/it]"]},{"name":"stdout","output_type":"stream","text":["2786/2786 [==============================] - 39s 13ms/step - loss: 0.0015 - si_snr: 47.0293 - val_loss: 0.0013 - val_si_snr: 47.7522 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["14it [11:19, 47.43s/it]"]},{"name":"stdout","output_type":"stream","text":["2721/2721 [==============================] - 38s 13ms/step - loss: 0.0014 - si_snr: 47.5606 - val_loss: 0.0013 - val_si_snr: 48.0072 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["15it [12:04, 46.45s/it]"]},{"name":"stdout","output_type":"stream","text":["2739/2739 [==============================] - 36s 13ms/step - loss: 0.0011 - si_snr: 47.8246 - val_loss: 0.0013 - val_si_snr: 48.0662 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["16it [12:46, 45.11s/it]"]},{"name":"stdout","output_type":"stream","text":["2685/2685 [==============================] - 35s 12ms/step - loss: 0.0011 - si_snr: 48.2828 - val_loss: 9.6753e-04 - val_si_snr: 48.3306 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["17it [13:27, 43.87s/it]"]},{"name":"stdout","output_type":"stream","text":["2972/2972 [==============================] - 38s 12ms/step - loss: 0.0013 - si_snr: 47.5068 - val_loss: 0.0011 - val_si_snr: 48.3345 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["18it [14:11, 44.13s/it]"]},{"name":"stdout","output_type":"stream","text":["2967/2967 [==============================] - 36s 11ms/step - loss: 0.0016 - si_snr: 47.1265 - val_loss: 0.0015 - val_si_snr: 48.1552 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["19it [14:54, 43.67s/it]"]},{"name":"stdout","output_type":"stream","text":["2309/2309 [==============================] - 30s 12ms/step - loss: 0.0012 - si_snr: 48.0883 - val_loss: 0.0010 - val_si_snr: 48.5546 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["20it [15:30, 41.27s/it]"]},{"name":"stdout","output_type":"stream","text":["3044/3044 [==============================] - 39s 12ms/step - loss: 0.0016 - si_snr: 46.8080 - val_loss: 0.0014 - val_si_snr: 47.4668 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["21it [16:16, 42.75s/it]"]},{"name":"stdout","output_type":"stream","text":["2687/2687 [==============================] - 35s 12ms/step - loss: 0.0011 - si_snr: 48.0766 - val_loss: 0.0010 - val_si_snr: 48.2041 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["22it [16:56, 42.02s/it]"]},{"name":"stdout","output_type":"stream","text":["3139/3139 [==============================] - 37s 11ms/step - loss: 0.0013 - si_snr: 47.7472 - val_loss: 0.0013 - val_si_snr: 48.6537 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["23it [17:40, 42.57s/it]"]},{"name":"stdout","output_type":"stream","text":["2758/2758 [==============================] - 35s 12ms/step - loss: 0.0013 - si_snr: 47.5296 - val_loss: 0.0011 - val_si_snr: 47.6042 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["24it [18:21, 42.21s/it]"]},{"name":"stdout","output_type":"stream","text":["2361/2361 [==============================] - 30s 12ms/step - loss: 0.0014 - si_snr: 47.1249 - val_loss: 0.0013 - val_si_snr: 47.9865 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["25it [18:57, 40.21s/it]"]},{"name":"stdout","output_type":"stream","text":["3132/3132 [==============================] - 39s 12ms/step - loss: 0.0010 - si_snr: 48.6312 - val_loss: 8.9362e-04 - val_si_snr: 48.5262 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["26it [19:45, 42.49s/it]"]},{"name":"stdout","output_type":"stream","text":["3201/3201 [==============================] - 40s 12ms/step - loss: 0.0013 - si_snr: 47.7124 - val_loss: 0.0012 - val_si_snr: 48.3771 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["27it [20:33, 44.26s/it]"]},{"name":"stdout","output_type":"stream","text":["2858/2858 [==============================] - 36s 12ms/step - loss: 0.0012 - si_snr: 48.6358 - val_loss: 0.0012 - val_si_snr: 49.6303 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["28it [21:16, 43.96s/it]"]},{"name":"stdout","output_type":"stream","text":["2714/2714 [==============================] - 35s 12ms/step - loss: 0.0013 - si_snr: 47.5371 - val_loss: 0.0011 - val_si_snr: 48.3240 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["29it [21:57, 43.04s/it]"]},{"name":"stdout","output_type":"stream","text":["2904/2904 [==============================] - 36s 12ms/step - loss: 9.6488e-04 - si_snr: 48.9597 - val_loss: 8.0514e-04 - val_si_snr: 50.1160 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["30it [22:40, 42.90s/it]"]},{"name":"stdout","output_type":"stream","text":["2704/2704 [==============================] - 35s 12ms/step - loss: 0.0015 - si_snr: 47.3775 - val_loss: 0.0012 - val_si_snr: 48.1606 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["31it [23:20, 42.10s/it]"]},{"name":"stdout","output_type":"stream","text":["2491/2491 [==============================] - 33s 12ms/step - loss: 0.0015 - si_snr: 47.4932 - val_loss: 0.0013 - val_si_snr: 47.8773 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["32it [23:58, 40.97s/it]"]},{"name":"stdout","output_type":"stream","text":["3205/3205 [==============================] - 41s 12ms/step - loss: 0.0014 - si_snr: 46.7926 - val_loss: 0.0013 - val_si_snr: 47.6018 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["33it [24:47, 43.35s/it]"]},{"name":"stdout","output_type":"stream","text":["2688/2688 [==============================] - 35s 12ms/step - loss: 0.0012 - si_snr: 47.9336 - val_loss: 0.0010 - val_si_snr: 48.8053 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["34it [25:27, 42.37s/it]"]},{"name":"stdout","output_type":"stream","text":["3119/3119 [==============================] - 39s 12ms/step - loss: 0.0011 - si_snr: 48.3049 - val_loss: 0.0010 - val_si_snr: 48.7323 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["35it [26:14, 43.73s/it]"]},{"name":"stdout","output_type":"stream","text":["2706/2706 [==============================] - 35s 12ms/step - loss: 0.0012 - si_snr: 47.4022 - val_loss: 0.0012 - val_si_snr: 48.8059 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["36it [26:55, 42.78s/it]"]},{"name":"stdout","output_type":"stream","text":["3217/3217 [==============================] - 41s 12ms/step - loss: 0.0013 - si_snr: 47.9504 - val_loss: 0.0012 - val_si_snr: 49.3741 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["37it [27:43, 44.53s/it]"]},{"name":"stdout","output_type":"stream","text":["2803/2803 [==============================] - 36s 12ms/step - loss: 0.0012 - si_snr: 48.9052 - val_loss: 0.0011 - val_si_snr: 48.9361 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["38it [28:26, 44.06s/it]"]},{"name":"stdout","output_type":"stream","text":["3160/3160 [==============================] - 41s 12ms/step - loss: 0.0018 - si_snr: 46.0664 - val_loss: 0.0016 - val_si_snr: 46.9544 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["39it [29:17, 46.03s/it]"]},{"name":"stdout","output_type":"stream","text":["2685/2685 [==============================] - 34s 12ms/step - loss: 0.0011 - si_snr: 48.8418 - val_loss: 0.0010 - val_si_snr: 49.6892 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["40it [29:59, 44.74s/it]"]},{"name":"stdout","output_type":"stream","text":["2776/2776 [==============================] - 36s 12ms/step - loss: 0.0013 - si_snr: 48.1081 - val_loss: 0.0012 - val_si_snr: 48.2655 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["41it [30:43, 44.56s/it]"]},{"name":"stdout","output_type":"stream","text":["2863/2863 [==============================] - 37s 12ms/step - loss: 9.6699e-04 - si_snr: 48.5951 - val_loss: 8.4416e-04 - val_si_snr: 49.9430 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["42it [31:26, 44.02s/it]"]},{"name":"stdout","output_type":"stream","text":["2837/2837 [==============================] - 37s 12ms/step - loss: 0.0011 - si_snr: 48.6429 - val_loss: 9.3645e-04 - val_si_snr: 49.6405 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["43it [32:09, 43.69s/it]"]},{"name":"stdout","output_type":"stream","text":["2713/2713 [==============================] - 35s 12ms/step - loss: 0.0011 - si_snr: 48.3390 - val_loss: 0.0010 - val_si_snr: 49.4008 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["44it [32:49, 42.87s/it]"]},{"name":"stdout","output_type":"stream","text":["2841/2841 [==============================] - 36s 12ms/step - loss: 0.0011 - si_snr: 49.1528 - val_loss: 9.5910e-04 - val_si_snr: 49.9281 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["45it [33:31, 42.61s/it]"]},{"name":"stdout","output_type":"stream","text":["3179/3179 [==============================] - 40s 12ms/step - loss: 0.0013 - si_snr: 48.4492 - val_loss: 0.0013 - val_si_snr: 46.5816 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["46it [34:20, 44.35s/it]"]},{"name":"stdout","output_type":"stream","text":["3172/3172 [==============================] - 39s 12ms/step - loss: 9.4605e-04 - si_snr: 48.9625 - val_loss: 8.3390e-04 - val_si_snr: 50.0179 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["47it [35:07, 45.07s/it]"]},{"name":"stdout","output_type":"stream","text":["2927/2927 [==============================] - 38s 12ms/step - loss: 0.0011 - si_snr: 47.7979 - val_loss: 0.0012 - val_si_snr: 48.5005 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["48it [35:51, 44.82s/it]"]},{"name":"stdout","output_type":"stream","text":["2831/2831 [==============================] - 37s 12ms/step - loss: 0.0012 - si_snr: 48.0895 - val_loss: 9.5881e-04 - val_si_snr: 49.1129 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["49it [36:34, 44.18s/it]"]},{"name":"stdout","output_type":"stream","text":["2969/2969 [==============================] - 37s 12ms/step - loss: 0.0017 - si_snr: 47.2830 - val_loss: 0.0015 - val_si_snr: 48.7684 - lr: 8.0000e-05\n"]},{"name":"stderr","output_type":"stream","text":["50it [37:18, 44.77s/it]\n"]},{"name":"stdout","output_type":"stream","text":["4890/4890 [==============================] - 19s 4ms/step\n","1/1 [==============================] - 0s 19ms/step\n","file saved: snln=64_cmpr=0.2_loss=snipLoss_SNR=17.0.wav\n","evaluating 10 test songs\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["4890/4890 - 19s - loss: 0.0148 - si_snr: 31.8577 - 19s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:19, 19.68s/it]"]},{"name":"stdout","output_type":"stream","text":["5982/5982 - 24s - loss: 0.0166 - si_snr: 31.6003 - 24s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2it [01:13, 36.61s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m plotWave(autoencoder, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_folder\u001b[39m}\u001b[39;00m\u001b[39mtrain_compression_rates/modelCompressionRate:\u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mwave_\u001b[39m\u001b[39m'\u001b[39m, c)\n\u001b[1;32m    128\u001b[0m autoencoder\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_folder\u001b[39m}\u001b[39;00m\u001b[39mtrain_compression_rates/modelCompressionRate:\u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.keras\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m testPerformance \u001b[39m=\u001b[39m evaluateTestSongs(autoencoder, num \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m)\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_folder\u001b[39m}\u001b[39;00m\u001b[39mtrain_compression_rates/modelCompressionRate:\u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mPerformance.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, newline\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    132\u001b[0m   \u001b[39m# Create a CSV writer\u001b[39;00m\n\u001b[1;32m    133\u001b[0m   writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(file)\n","Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mevaluateTestSongs\u001b[0;34m(autoencoder, num)\u001b[0m\n\u001b[1;32m     15\u001b[0m     songSnip \u001b[39m=\u001b[39m cut(song, snippitLength)\n\u001b[1;32m     17\u001b[0m     songSnip_transformed \u001b[39m=\u001b[39m MinMaxScaler()\u001b[39m.\u001b[39mfit_transform(songSnip)\n\u001b[0;32m---> 18\u001b[0m     test_loss, test_si_snr \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mevaluate(songSnip_transformed, songSnip_transformed, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m     test_evaluated\u001b[39m.\u001b[39mappend([songname, test_loss, test_si_snr])\n\u001b[1;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m test_evaluated\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2070\u001b[0m ):\n\u001b[1;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"text/plain":["<Figure size 1200x600 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 3600x1200 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 3600x1200 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Find best topology across different compression ratios and build/train 10 models across compression ratios with that topology\n","import csv\n","\n","def read_histories_from_csv(file_path):\n","    histories = {}\n","    with open(file_path, 'r') as csvfile:\n","        reader = csv.reader(csvfile)\n","        next(reader)  # Skip the header row\n","        for row in reader:\n","            filename = row[0]\n","            loss = float(row[1])\n","            val_loss = float(row[2])\n","            histories[filename] = {'loss': [loss], 'val_loss': [val_loss]}\n","    return histories\n","\n","# tf.random.set_seed(42+300)\n","\n","\n","# parSet_sum = {}\n","# search_results_json = output_folder + 'hyperparamsearch/' + 'searchResults.json'\n","# search_results_json = 'output/Versuch1_11.07.2023/searchResults.json'\n","# search_results_json = 'output/Versuch3_13.07.2023/hyperparamsearch/searchResults_170songs_5epochs_final.json'\n","# with open(search_results_json, 'r') as file:\n","#     search_results = json.load(file)\n","\n","# for item in search_results:\n","#     numDense = item['numDense']\n","#     numConv = item['numConv']\n","#     numConvLayer = item['numConvLayer']\n","#     best_val_si_snr = item['best_val_si_snr']\n","\n","#     key = (numDense, numConv, numConvLayer)\n","#     if key in parSet_sum:\n","#        parSet_sum[key] += best_val_si_snr\n","#     else:\n","#         parSet_sum[key] = best_val_si_snr\n","\n","# keys = [k for k in parSet_sum.keys()]\n","# si_snr_sum = [parSet_sum[k] for k in keys]\n","# bestParSet = keys[np.argmax(si_snr_sum)]\n","\n","\n","\n","# print(f'best set : {bestParSet}')\n","\n","# compression_rates = np.linspace(0.1,0.9,9) # todo\n","compression_rates = [0.2]\n","# silence_prob = 0.01\n","\n","numTopoTrainSongs = 1 # 6 min \n","numTopoEpochs = 1\n","\n","numTotalSongs = 17\n","percentage_of_song = float(1/(numTotalSongs))\n","\n","total_num_songs = len(fileNames)\n","numTopoTrainSongs = int(((total_num_songs*0.7)+1))\n","# numTopoTrainSongs = numTopoTrainSongs*4\n","numTopoEpochs = 1\n","\n","learning_rate = 0.1 # nooo\n","learning_rate = 0.01 # nooo\n","learning_rate = 0.0001 #no\n","learning_rate = 0.0005\n","learning_rate = 0.005  # 20\n","learning_rate = 0.003  # 36\n","learning_rate = 0.0004  # better and slow up trend should be ok\n","learning_rate = 0.0008  # better and slow up trend\n","learning_rate = 0.0004 #no\n","learning_rate = 0.001 #30 ish\n","learning_rate = 0.0006  # better and slow up trend\n","learning_rate = 0.0002 #no\n","learning_rate = 0.00008 #no\n","\n","numTestSongs = int(total_num_songs*0.3)\n","model_save_path = output_folder + 'hyperparamsearch/' + f'model_train1_1024_5.keras' #20\n","model_save_path = output_folder + 'hyperparamsearch/' + f'model_train1_256_3.keras' #20\n","model_save_path = output_folder + 'train_compression_rates/' + f'model_train1_128_3.keras' #20\n","model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3_zweite.keras' #100\n","histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train1_128_3.csv'\n","histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train_1_96_3.csv'\n","def lr_schedule(epoch):\n","  return learning_rate\n","# autoencoder = tf.keras.models.load_model(model_save_path)\n","# break\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","for c in compression_rates:\n","  # autoencoder = buildModel(c, bestParSet[0],bestParSet[1],bestParSet[2], learning_rate = learning_rate)\n","  autoencoder = buildModel(c, 1, 96, 3, learning_rate = learning_rate)\n","  # autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","  histories = {}\n","  batch_size=512\n","  batch_size=2**12\n","  batch_size=2**8  #256\n","  batch_size=2**7  #128 # train and val diverging by +0.1\n","  batch_size=2**6  #64\n","  numTopoTrainSongs = 50\n","  for idx, filename_train in tqdm(enumerate(fileNames[0:numTopoTrainSongs:])):\n","    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n","    histories[filename_train] = autoencoder.fit(Xt, Xt,\n","                epochs=numTopoEpochs,\n","                batch_size=batch_size,\n","                shuffle=True,\n","                validation_data=(Xv, Xv),\n","                callbacks=[lr_scheduler])\n","    del Xt\n","    del Xv\n","    save_period = int(9/numHyperEpochs)\n","    save_period = 1\n","    if (idx % save_period == 0) and (idx != 0):\n","      autoencoder.save(model_save_path)\n","      del autoencoder\n","      autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","      # with open(histories_save_path, 'w', newline='') as csvfile:\n","      #     writer = csv.writer(csvfile)\n","      #     writer.writerow(['filename', 'loss', 'val_loss'])\n","      #     for key, value in histories.items():\n","      #         writer.writerow([key, value.history['loss'][0], value.history['val_loss'][0]], value.history['loss'][0])\n","  tf.keras.backend.clear_session()\n","  \n","  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n","  # histories = read_histories_from_csv(histories_save_path)\n","  plot_history(histories, output_folder + 'train_compression_rates/' + pdfname)\n","  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n","\n","  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n","  testPerformance = evaluateTestSongs(autoencoder, num = 10)\n","\n","  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n","    # Create a CSV writer\n","    writer = csv.writer(file)\n","\n","    # Write the data row by row\n","    for row in testPerformance:\n","        writer.writerow(row)\n","\n","  # break\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["evaluating 10 test songs\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["4890/4890 - 19s - loss: 0.0194 - si_snr: 30.7520 - 19s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:19, 19.74s/it]"]},{"name":"stdout","output_type":"stream","text":["5982/5982 - 22s - loss: 0.0131 - si_snr: 32.8698 - 22s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2it [00:42, 21.49s/it]"]},{"name":"stdout","output_type":"stream","text":["11000/11000 - 41s - loss: 0.0146 - si_snr: 32.4035 - 41s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["3it [01:24, 30.67s/it]"]},{"name":"stdout","output_type":"stream","text":["12679/12679 - 47s - loss: 0.0154 - si_snr: 31.4892 - 47s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["4it [02:11, 37.47s/it]"]},{"name":"stdout","output_type":"stream","text":["2844/2844 - 11s - loss: 0.0193 - si_snr: 30.9623 - 11s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["5it [02:23, 28.04s/it]"]},{"name":"stdout","output_type":"stream","text":["3229/3229 - 13s - loss: 0.0284 - si_snr: 29.2864 - 13s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["6it [02:36, 22.96s/it]"]},{"name":"stdout","output_type":"stream","text":["4298/4298 - 17s - loss: 0.0285 - si_snr: 28.7615 - 17s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["7it [02:53, 20.99s/it]"]},{"name":"stdout","output_type":"stream","text":["2411/2411 - 9s - loss: 0.0242 - si_snr: 30.2862 - 9s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["8it [03:02, 17.30s/it]"]},{"name":"stdout","output_type":"stream","text":["4062/4062 - 15s - loss: 0.0147 - si_snr: 32.2009 - 15s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["9it [03:18, 16.76s/it]"]},{"name":"stdout","output_type":"stream","text":["8304/8304 - 31s - loss: 0.0195 - si_snr: 30.3084 - 31s/epoch - 4ms/step\n"]},{"name":"stderr","output_type":"stream","text":["10it [03:49, 22.97s/it]\n"]}],"source":["testPerformance = evaluateTestSongs(autoencoder, num = 10)\n","\n","with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n","# Create a CSV writer\n","    writer = csv.writer(file)\n","\n","    # Write the data row by row\n","    for row in testPerformance:\n","        writer.writerow(row)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0.05"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["numTotalSongs = 20\n","percentage_of_song = 1/(numTotalSongs)\n","percentage_of_song"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4045/4890 [=======================>......] - ETA: 3s"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m autoencoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(model_save_path)\n\u001b[0;32m----> 3\u001b[0m plotWave(autoencoder, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_folder\u001b[39m}\u001b[39;49;00m\u001b[39mtrain_compression_rates/modelCompressionRate:\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39m0.2\u001b[39;49m\u001b[39m:\u001b[39;49;00m\u001b[39m.1f\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39mwave_\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0.2\u001b[39;49m)\n","Cell \u001b[0;32mIn[14], line 19\u001b[0m, in \u001b[0;36mplotWave\u001b[0;34m(autoencoder, name, compression_ratio)\u001b[0m\n\u001b[1;32m     16\u001b[0m   origSnip_transformed \u001b[39m=\u001b[39m scaler_Example\u001b[39m.\u001b[39mfit_transform(origSnip)\n\u001b[1;32m     18\u001b[0m \u001b[39m# autoencode song\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m a \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mpredict(origSnip_transformed)\n\u001b[1;32m     20\u001b[0m a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, snippitLength)\n\u001b[1;32m     21\u001b[0m XpredSnip \u001b[39m=\u001b[39m scaler_Example\u001b[39m.\u001b[39minverse_transform(a)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2403\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2394\u001b[0m                 tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m   2395\u001b[0m                     batch_outputs,\n\u001b[1;32m   2396\u001b[0m                     \u001b[39mlambda\u001b[39;00m output, batch_output: output\u001b[39m.\u001b[39mappend(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2400\u001b[0m                     batch_outputs,\n\u001b[1;32m   2401\u001b[0m                 )\n\u001b[1;32m   2402\u001b[0m             end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 2403\u001b[0m             callbacks\u001b[39m.\u001b[39;49mon_predict_batch_end(\n\u001b[1;32m   2404\u001b[0m                 end_step, {\u001b[39m\"\u001b[39;49m\u001b[39moutputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: batch_outputs}\n\u001b[1;32m   2405\u001b[0m             )\n\u001b[1;32m   2406\u001b[0m \u001b[39mif\u001b[39;00m batch_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `predict_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty batch_outputs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2414\u001b[0m     )\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:519\u001b[0m, in \u001b[0;36mCallbackList.on_predict_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_predict_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \n\u001b[1;32m    514\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_predict_batch_hooks:\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mPREDICT, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:1101\u001b[0m, in \u001b[0;36mProgbarLogger.on_predict_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_predict_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1100\u001b[0m     \u001b[39m# Don't pass prediction results.\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, \u001b[39mNone\u001b[39;49;00m)\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:1155\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Updates the progbar.\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m logs \u001b[39m=\u001b[39m logs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m-> 1155\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_init_progbar()\n\u001b[1;32m   1156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_steps:\n\u001b[1;32m   1157\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m=\u001b[39m batch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# One-indexed.\u001b[39;00m\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py:1130\u001b[0m, in \u001b[0;36mProgbarLogger._maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics)\n\u001b[1;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel:\n\u001b[1;32m   1126\u001b[0m     \u001b[39m# Update the existing stateful metrics as `self.model.metrics` may\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39m# contain updated metrics after `MetricsContainer` is built in the\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[39m# first train step.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics\u001b[39m.\u001b[39munion(\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mset\u001b[39m(m\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmetrics)\n\u001b[1;32m   1131\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar \u001b[39m=\u001b[39m Progbar(\n\u001b[1;32m   1135\u001b[0m         target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget,\n\u001b[1;32m   1136\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   1137\u001b[0m         stateful_metrics\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics,\n\u001b[1;32m   1138\u001b[0m         unit_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_steps \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msample\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     )\n","File \u001b[0;32m~/.local/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:849\u001b[0m, in \u001b[0;36mModel.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m         metrics \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics\u001b[39m.\u001b[39mmetrics\n\u001b[1;32m    848\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_layers():\n\u001b[0;32m--> 849\u001b[0m     metrics\u001b[39m.\u001b[39mextend(l\u001b[39m.\u001b[39;49m_metrics)\n\u001b[1;32m    850\u001b[0m \u001b[39mreturn\u001b[39;00m metrics\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{0.2:.1f}wave_', 0.2)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'numTopoTrainSongs' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m filename_train \u001b[39min\u001b[39;00m tqdm(fileNames[:numTopoTrainSongs]):\n\u001b[1;32m      2\u001b[0m   Xt, Xv \u001b[39m=\u001b[39m loadSongCut(filename_train, silence_prob \u001b[39m=\u001b[39m silence_prob)\n\u001b[1;32m      3\u001b[0m   histories[filename_train] \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mfit(Xt, Xt,\n\u001b[1;32m      4\u001b[0m               epochs\u001b[39m=\u001b[39mnumTopoEpochs,\n\u001b[1;32m      5\u001b[0m               batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      6\u001b[0m               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m               validation_data\u001b[39m=\u001b[39m(Xv, Xv))\n","\u001b[0;31mNameError\u001b[0m: name 'numTopoTrainSongs' is not defined"]}],"source":["  for filename_train in tqdm(fileNames[:numTopoTrainSongs]):\n","    Xt, Xv = loadSongCut(filename_train, silence_prob = silence_prob)\n","    histories[filename_train] = autoencoder.fit(Xt, Xt,\n","                epochs=numTopoEpochs,\n","                batch_size=2**10,\n","                shuffle=True,\n","                validation_data=(Xv, Xv))\n","    \n","  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n","  plot_history(histories, output_folder + 'train_compression_rates/' + pdfname)\n","\n","  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n","  testPerformance = evaluateTestSongs(autoencoder)\n","\n","  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n","    # Create a CSV writer\n","    writer = csv.writer(file)\n","\n","    # Write the data row by row\n","    for row in testPerformance:\n","        writer.writerow(row)\n","  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n","\n","  break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgKZrEl6CGnU","tags":["fit"]},"outputs":[],"source":["# #numTrainSongs =\n","# batch_size = 2**10\n","# epochs = 5\n","# histories = {}\n","# for fn in tqdm(fileNames[:numTrainSongs]):\n","#   Xt, Xv = loadSongCut(fn)\n","#   Xt = np.array(Xt)\n","#   Xv = np.array(Xv)\n","#   histories[fn] = autoencoder.fit(Xt, Xt,\n","#                 epochs=epochs,\n","#                 batch_size=batch_size,\n","#                 shuffle=True,\n","#                 validation_data=(Xv, Xv))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
