{"cells":[{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1689112172443,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"syn0nt6E1bOO"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","# import tensorrt\n","#ImportError: Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.9.17 (main, Jul  5 2023, 20:41:20) \n","#[GCC 11.2.0].\n","# print(tf.__file__)\n","# import os\n","# print(os.environ['LD_LIBRARY_PATH'])\n","from tensorflow.keras.layers import Input, Dense,Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import get_custom_objects\n","from tensorflow.keras import backend as K\n","from tensorflow.python.ops import math_ops\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from tqdm import tqdm\n","from scipy.io import wavfile\n","import random\n","import itertools\n","import json\n","# from google.colab import drive"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: /home/martin/.local/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: import-ipynb in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (0.1.4)\n","Requirement already satisfied: IPython in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from import-ipynb) (8.14.0)\n","Requirement already satisfied: nbformat in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from import-ipynb) (5.9.1)\n","Requirement already satisfied: backcall in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: decorator in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.18.2)\n","Requirement already satisfied: matplotlib-inline in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.1.6)\n","Requirement already satisfied: pickleshare in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (3.0.39)\n","Requirement already satisfied: pygments>=2.4.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (2.15.1)\n","Requirement already satisfied: stack-data in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (5.9.0)\n","Requirement already satisfied: typing-extensions in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (4.5.0)\n","Requirement already satisfied: pexpect>4.3 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: fastjsonschema in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (2.17.1)\n","Requirement already satisfied: jsonschema>=2.6 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (4.18.3)\n","Requirement already satisfied: jupyter-core in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->import-ipynb) (5.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n","Requirement already satisfied: attrs>=22.2.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.6.1)\n","Requirement already satisfied: referencing>=0.28.4 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.29.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.8.10)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->import-ipynb) (0.2.6)\n","Requirement already satisfied: platformdirs>=2.5 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from jupyter-core->nbformat->import-ipynb) (3.8.1)\n","Requirement already satisfied: executing>=1.2.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (1.2.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (2.2.1)\n","Requirement already satisfied: pure-eval in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n","Requirement already satisfied: six in /home/martin/.local/anaconda3/envs/tf/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->IPython->import-ipynb) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install import-ipynb"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1689112112219,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"GqBX39TFv-Rz"},"outputs":[],"source":["def cut(arr, length):\n","  idx = len(arr)%length\n","  out = []\n","  while(idx+length <= len(arr)):\n","    out.append(arr[idx:idx+length])\n","    idx += length\n","  return np.array(out)\n","\n","def loadSong(fName, numTotalSongs = 1):\n","  fs, data = wavfile.read(inpathTrain + fName)\n","  all_data = [data]\n","\n","  if numTotalSongs > 1:\n","    seed = sum([ord(char) for char in fName])\n","    random.seed(seed)\n","    file_nams = random.sample(fileNames[:170], numTotalSongs-1)\n","    for name in file_nams:\n","      fs, data1 = wavfile.read(inpathTrain + name)\n","      all_data.append(data1)\n","\n","  \n","  concatenated_data = np.concatenate(all_data)\n","  if concatenated_data.ndim > 1:\n","    mono_data = np.mean(concatenated_data, axis=1)\n","  else:\n","    mono_data = concatenated_data\n","\n","  # # all_data.append(data)\n","\n","  # # all_data = np.concatenate(data, data1)\n","  # for name in file_nams:\n","  #   fs, data1 = wavfile.read(inpathTrain + name)\n","  #   data = np.concatenate(data, data1)\n","  #   # all_data.append(data)\n","\n","  # all_data = np.array(data)\n","  # if data.ndim > 1:\n","  #   mono_data = np.mean(all_data, axis=1)\n","  # else:\n","  #   mono_data = all_data\n","\n","  return mono_data.astype('int16')\n","\n","def loadSongCut(fName, silence_prob = 0, numTotalSongs = 1, percentage_of_song = 1):\n","  data = loadSong(fName, numTotalSongs)\n","  data = cut(data, snippitLength)\n","\n","  # Replace rows with silence based on silence_prob\n","  if silence_prob!=0:\n","    num_rows = data.shape[0]\n","    num_silence_rows = int(num_rows * silence_prob)\n","    silence_rows = np.zeros((num_silence_rows, data.shape[1]))\n","    data[:num_silence_rows, :] = silence_rows\n","\n","\n","  scaler[fName] = MinMaxScaler()\n","  #data = quadratic_scaler(data, 5)\n","  data = scaler[fName].fit_transform(data)\n","\n","  Xt, Xv = train_test_split(data, test_size=0.3, random_state=42)\n","  if percentage_of_song != 1:\n","    index_t = int(len(Xt)*percentage_of_song)\n","    index_v = int(len(Xv)*percentage_of_song)\n","    Xt = Xt[:index_t]\n","    Xv = Xv[:index_v]\n","  return np.array(Xt), np.array(Xv)\n","\n","\n","\n","\n","def loadSongCut_tensor(fName, silence_prob = 0):\n","\n","  Xt, Xv = loadSongCut(fName, silence_prob)\n","\n","  # Convert NumPy arrays to TensorFlow tensors\n","  # Xt_tensor = tf.constant(Xt, dtype=tf.float32)\n","  # Xv_tensor = tf.constant(Xv, dtype=tf.float32)\n","  Xt_tensor = tf.constant(Xt, dtype=tf.int16)\n","  Xv_tensor = tf.constant(Xv, dtype=tf.int16)\n","\n","  # Create datasets from TensorFlow tensors\n","  dataset_Xt = tf.data.Dataset.from_tensor_slices(Xt_tensor)\n","  dataset_Xv = tf.data.Dataset.from_tensor_slices(Xv_tensor)\n","\n","  batch_size = 32  # Adjust according to memory availability and training efficiency\n","  buffer_size = 10000  # Set to a value larger than the dataset size but still fits in memory\n","  prefetch_size = 1  # Increase if input pipeline is a bottleneck, otherwise keep it low\n","\n","\n","  # Configure the datasets\n","  dataset_Xt = dataset_Xt.batch(batch_size)  # Set batch size\n","  dataset_Xt = dataset_Xt.shuffle(buffer_size=buffer_size)  # Enable shuffling\n","  dataset_Xt = dataset_Xt.prefetch(prefetch_size)  # Enable prefetching\n","\n","  dataset_Xv = dataset_Xv.batch(batch_size)  # Set batch size\n","  dataset_Xv = dataset_Xv.shuffle(buffer_size=buffer_size)  # Enable shuffling\n","  dataset_Xv = dataset_Xv.prefetch(prefetch_size)  # Enable prefetching\n","\n","  return dataset_Xt, dataset_Xv\n","\n","def digital_decibel(x):\n","  if (x>0):\n","    decibels = 1/ (10 * np.log10(x/1))\n","  else:\n","    decibels = 1 / (-1*  10 * np.log10(-x/1))\n","  return decibels\n","\n","def quadratic_scaler(x, n):\n","  v = [i**n for i in x]\n","  return v\n","\n","# s = loadSong('2633_ps10_03.wav', 2)\n","# wavfile.write('test.wav', 44100, s)\n","\n","# t, v = loadSongCut('2633_ps10_03.wav', numTotalSongs = 2, percentage_of_song = 0.1)\n","# t, v = loadSongCut('2633_ps10_03.wav') # ((93324, 64), (39996, 64))\n","# t, v = loadSongCut('2633_ps10_03.wav', numTotalSongs = 3, percentage_of_song = 0.3)\n","# t.shape, v.shape\n","# (45307, 64)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689112113489,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"KoAFMHZoABRx"},"outputs":[],"source":["def snipLoss(y_true, y_pred):\n","  snipWeight = tf.convert_to_tensor([int(np.cosh(x)) for x in range(-5, 5, snippitLength)], dtype='float32')\n","\n","  loss = math_ops.squared_difference(y_true,y_pred)\n","  loss = math_ops.Mul(x = loss,y = snipWeight)\n","  loss = math_ops.log1p(loss)\n","  return loss\n","\n","def si_snr2(y_true, y_pred):\n","  # Remove extra dimensions\n","  y_true = tf.squeeze(y_true)\n","  y_pred = tf.squeeze(y_pred)\n","\n","  # Compute the scaling factor\n","  scale = tf.reduce_sum(y_true * y_pred) / tf.reduce_sum(y_pred * y_pred)\n","\n","  # Compute the estimated source and the target source\n","  est_source = scale * y_pred\n","  target_source = y_true\n","\n","  # Compute the noise source\n","  noise_source = est_source - target_source\n","\n","  # Compute the SI-SNR\n","  numerator = tf.reduce_sum(target_source * est_source, axis=-1)\n","  denominator = tf.reduce_sum(noise_source * noise_source, axis=-1)\n","  si_snr = 10 * tf.math.log(numerator / denominator + 1e-8) / tf.math.log(10.0)\n","\n","  # Return the average SI-SNR\n","  return tf.reduce_mean(si_snr)\n","\n","def si_snr(original, estimate):\n","  # original and estimate are tensors of shape (batch_size, time_steps)\n","  # compute the dot product of original and estimate along the time axis\n","  dot = tf.reduce_sum(original * estimate, axis=-1, keepdims=True)\n","  denominator = tf.reduce_sum(original ** 2, axis=-1, keepdims=True)\n","  # compute the scaled target\n","  scaled_target = dot * original / denominator\n","  # compute the noise\n","  e_noise = estimate - scaled_target\n","  # compute the SI-SNR in decibels\n","  si_snr = 10 * tf.math.log(tf.reduce_sum(scaled_target ** 2, axis=-1) / tf.reduce_sum(e_noise ** 2, axis=-1)) / tf.math.log(10.0)\n","  # return the SI-SNR tensor of shape (batch_size,)\n","  return si_snr"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4029,"status":"ok","timestamp":1689112280618,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"YqamE_X1B0On","outputId":"1e058a44-8385-4e82-db5a-f15abc0c90ea"},"outputs":[],"source":["# paths\n","# drive.mount('/content/drive')\n","# inpathTrain = \"/content/drive/MyDrive/Machine Learning/Autoencoder/train_data/\"\n","# inpathOut = \"/content/drive/MyDrive/Machine Learning/Autoencoder/output/\"\n","inpathTrain = \"/mnt/e/data/SynologyDrive/Uni/mSem02/Machine Learning/Project_Audio_Autoencoder/musicnet_midis/BOT/Mixdown/output/\"\n","inpathOut =   \"/home/martin/martin_user_data/jupyter_notebooks/autoencoder_ml/output/\"\n","output_folder = \"output/Versuch3_13.07.2023/\"\n","fileNames = os.listdir(inpathTrain)\n","random.seed(42)\n","fileNames = random.sample(fileNames, len(fileNames))\n","\n","hyperparamsearch_folder = output_folder + 'hyperparamsearch'\n","train_compression_rates_folder = output_folder + 'train_compression_rates'\n","\n","if not os.path.exists(hyperparamsearch_folder):\n","    os.mkdir(hyperparamsearch_folder)\n","\n","if not os.path.exists(train_compression_rates_folder):\n","    os.mkdir(train_compression_rates_folder)\n","\n","scaler = {}\n","\n","# global variables\n","samplerate = 44_100\n","snippitLength = 64\n","\n","loss_fct = snipLoss\n","\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1689112243940,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"7Cl3Ffyg7uxx"},"outputs":[],"source":["####################################\n","#####  plot history\n","\n","def plot_loss(ax, network_history):\n","    loss = np.concatenate([network_history[key].history['loss'] for key in network_history.keys()])\n","    val_loss = np.concatenate([network_history[key].history['val_loss'] for key in network_history.keys()])\n","\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel('Loss')\n","    ax.set_title('Loss')\n","    ax.plot(loss, label='Training')\n","    ax.plot(val_loss, label='Validation')\n","    ax.legend()\n","\n","def plot_si_snr(ax, network_history):\n","    si_snr = np.concatenate([network_history[key].history['si_snr'] for key in network_history.keys()])\n","    val_si_snr = np.concatenate([network_history[key].history['val_si_snr'] for key in network_history.keys()])\n","\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel('SI_SNR')\n","    ax.set_title('SI-SNR')\n","    ax.plot(si_snr, label='Training')\n","    ax.plot(val_si_snr, label='Validation')\n","    ax.legend()\n","\n","def plot_history(network_history, name):\n","    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=False)\n","\n","    plot_loss(ax[0], network_history)\n","    plot_si_snr(ax[1], network_history)\n","\n","    plt.tight_layout()\n","    plt.savefig(name)\n","    # plt.show()\n","    plt.clf()\n"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1689112246220,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"v5Bv1lsxEPSL"},"outputs":[{"name":"stdout","output_type":"stream","text":["current model: ratio=0.5,numDense=1,numConv=8,numConvLayer=0\n","1/1 [==============================] - 1s 1s/step - loss: 0.5445 - si_snr: 12.8107 - val_loss: 0.8248 - val_si_snr: 13.4159\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fdf81b34a30>"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["####################################\n","#####  buildModel (Hyperparameter grid search)\n","# tf.random.set_seed(42)\n","def lr_schedule(epoch):\n","  if epoch < 10:\n","      return 0.01\n","  else:\n","      return 0.001\n","\n","# def buildModel(compression_ratio = 0.5, numDense = 2, numConv = 8,numConvLayer = 2, loss_fct = snipLoss, use_bias = False):\n","def buildModel(compression_ratio = 0.5, numDense = 1, numConv = 8,numConvLayer = 0, loss_fct = snipLoss, use_bias = False, learning_rate = 0.001):\n","\n","\n","\n","  latentSize = int(compression_ratio*snippitLength)\n","\n","  # keep tensorflow from allocating more memory as it currently needs\n","  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","  for i in physical_devices:\n","      tf.config.experimental.set_memory_growth(i, True)\n","  tf.device('/device:GPU:0')\n","\n","  input = Input(shape=(snippitLength,1))\n","  x = input\n","\n","  # Convolutional part of encoder\n","  for i in range(numConvLayer):\n","    x = Conv1D(numConv, 5, activation='relu', padding='same')(x)\n","    x = MaxPooling1D(2, padding = 'same')(x)\n","\n","  convShape = x.shape\n","  # calculate flatten dimension\n","  flsize = 1\n","  for i in x.shape:\n","    if(i != None):\n","      flsize*= i\n","\n","  # print(f'{latentSize} {flsize}')\n","  x = Flatten()(x)\n","\n","\n","  # Dense part of encoder\n","  denses = [int(i) for i in np.linspace(flsize, latentSize, numDense+1)]\n","  for i in denses[1:]:\n","    x = Dense(i, activation='relu', use_bias=use_bias)(x)\n","\n","  encoded = x\n","\n","  # for i in denses:\n","\n","  # Dense part of decoder\n","  x = encoded\n","  for i in denses[::-1][1:]:\n","    if(numConvLayer == 0 and i == snippitLength):\n","      x = Dense(i, activation='sigmoid')(x)\n","    else:\n","      x = Dense(i, activation='relu', use_bias=use_bias)(x)\n","\n","  if(numConvLayer == 0):\n","    decoded = x\n","\n","  x = Reshape(convShape[1:])(x)\n","\n","  # Convolutional part of decoder\n","  for i in range(numConvLayer):\n","    x = Conv1D(numConv,5, activation='relu', padding='same')(x)\n","    x = UpSampling1D(2)(x)\n","  if(numConvLayer != 0):\n","    decoded = Conv1D(1,5, activation='sigmoid', padding='same')(x)\n","\n","  autoencoder = Model(input, decoded)\n","  autoencoder = Model(input, Flatten()(decoded))\n","\n","  \n","  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fct, metrics=[si_snr])\n","  \n","  print(f'current model: ratio={compression_ratio},numDense={numDense},numConv={numConv},numConvLayer={numConvLayer}')\n","  # autoencoder.summary()\n","  return autoencoder\n","\n","\n","\n","get_custom_objects()['snipLoss'] = snipLoss\n","get_custom_objects()['si_snr'] = si_snr\n","Xt, Xv = loadSongCut('1727_schubert_op114_2.wav')\n","buildModel().fit(Xt[:2], Xt[:2],\n","            epochs=1,\n","            batch_size=512,\n","            shuffle=True,\n","            validation_data=(Xv[:2], Xv[:2]))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1689112249189,"user":{"displayName":"Thasa X","userId":"04839537513707422983"},"user_tz":-120},"id":"EcSaNyxC66NZ","outputId":"1f75acec-4823-494a-d349-049550b31de8"},"outputs":[{"name":"stdout","output_type":"stream","text":["estimated time = 4.2 h (6 sets)\n"]},{"data":{"text/plain":["[{'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 6}]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["param_space = {'compression_ratio' : [0.1, 0.2, 0.3, 0.4],\n","               'numDense' : [3, 4, 5, 6],\n","               'numConv' : [8, 16],\n","               'numConvLayer' : [0, 1, 2]}\n","\n","\n","\n","# param_space = {'compression_ratio' : np.linspace(0.1,0.9,2),\n","#                'numDense' : [2, 3],\n","#                'numConv' : [8, 6],\n","#                'numConvLayer' : np.linspace(0.1,0.2,2)} # small 1\n","# param_space = {'compression_ratio' : [0.1, 0.2],\n","#                'numDense' : [3,4],\n","#                'numConv' : [4, 8],\n","#                'numConvLayer' : [0, 1]} # small 2\n","\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [2, 3, 4, 5, 6],\n","               'numConv' : [8, 16, 24, 32],\n","               'numConvLayer' : [0, 1, 2, 3, 4]}\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [2, 3, 4],\n","               'numConv' : [32, 64],  # 128 too much memory need\n","               'numConvLayer' : [1, 2]}\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [1],\n","               'numConv' : [32, 64],  # 128 too much memory need\n","               'numConvLayer' : [1, 2]}\n","\n","\n","param_space = {'compression_ratio' : [0.2],\n","               'numDense' : [1],\n","               'numConv' : [64, 96, 128],\n","               'numConvLayer' : [4, 6]}\n","\n","\n","# param_space = {'compression_ratio' : [0.2],\n","#                'numDense' : [5, 6],\n","#                'numConv' : [24, 32],\n","#                'numConvLayer' : [ 3, 4]}\n","\n","numHyperTrainSongs = 120\n","numHyperTrainSongs = 170\n","numHyperTrainSongs = 70\n","numHyperEpochs = 1\n","# numHyperTrainSongs = 170\n","# numHyperEpochs = 10\n","\n","value_combis = itertools.product(*[v for v in param_space.values()])\n","param_combis = []\n","for combi in value_combis:\n","  param_combi = {key: value for key, value in zip(param_space.keys(), combi)}\n","  if param_combi['numConvLayer'] == 0:\n","    param_combi['numConv'] = 0\n","  param_combis.append(param_combi)\n","\n","# param_combis = [\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 2}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 32, 'numConvLayer': 3}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 2}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 64, 'numConvLayer': 3}, #47.8\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 2}, # 48.5\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 128, 'numConvLayer': 3}, # 48.5\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 2}, # 49.6\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 224, 'numConvLayer': 3}] # 49.6\n","\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 2}, # 48.2\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 3},\n","# param_combis = [\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 4},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 5},\n","#  {'compression_ratio': 0.2, 'numDense': 1, 'numConv': 96, 'numConvLayer': 6}]\n","\n","time_per_combi = 2.6\n","time_per_combi = 3*3.5*4\n","print(f'estimated time = {time_per_combi*len(param_combis)/60:.1f} h ({len(param_combis)} sets)')\n","# param_combis = param_combis[-1:]\n","# param_combis = reversed(param_combis)\n","param_combis = param_combis[5:]\n","param_combis"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"Iu7RTlE668_-","slideshow":{"slide_type":"slide"}},"outputs":[],"source":["# ####################################\n","# #####  Hyperparameter grid search\n","# import stopwatch as sw\n","\n","# t = sw.stopwatch(title='gridsearch', time_unit='s')\n","\n","# # Load existing results from the JSON file if it exists\n","# existing_results = []\n","# existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_3epochs.json'\n","# existing_file_path = output_folder + 'hyperparamsearch/' + 'searchResults_170songs_1epochs_final.json'\n","# if os.path.exists(existing_file_path):\n","#     with open(existing_file_path, 'r') as file:\n","#         existing_results = json.load(file)\n","\n","# random.seed(42)\n","# filename_random = random.sample(fileNames, 170)\n","# search_results = []\n","# model_save_path = output_folder + 'hyperparamsearch/' + f'model.keras'\n","# if os.path.exists(model_save_path):\n","#     os.remove(model_save_path)\n","\n","# for hyperParamSet in tqdm(param_combis):\n","#   autoencoder = buildModel(hyperParamSet['compression_ratio'],\n","#                            hyperParamSet['numDense'],\n","#                            hyperParamSet['numConv'],\n","#                            hyperParamSet['numConvLayer'])\n","\n","#   # autoencoder = buildModel()\n","#   histories = {}\n","#   # numHyperTrainSongs = 10\n","#   batch_size=4096\n","#   t.task('hyperparam')\n","#   for idx, filename_train in tqdm(enumerate(filename_random[:numHyperTrainSongs])):\n","#     Xt, Xv = loadSongCut(filename_train)\n","#     histories[filename_train] = autoencoder.fit(Xt, Xt,\n","#                 epochs=numHyperEpochs,\n","#                 batch_size=batch_size,\n","#                 shuffle=True,\n","#                 validation_data=(Xv, Xv))\n","#     del Xt\n","#     del Xv\n","#     if (idx % int(5/numHyperEpochs) == 0) and (idx != 0):\n","#       autoencoder.save(model_save_path)\n","#       del autoencoder\n","#       autoencoder = tf.keras.models.load_model(model_save_path)\n","#   t.stop()\n","#   del autoencoder\n","#   tf.keras.backend.clear_session()\n","\n","#   pdfname = f'HyperParOpt, compression_ratio= {hyperParamSet[\"compression_ratio\"]:.1f}, numDense= {hyperParamSet[\"numDense\"]}, numConvLayer= {hyperParamSet[\"numConvLayer\"]}, numConv= {hyperParamSet[\"numConv\"]}.pdf'\n","#   plot_history(histories, output_folder + 'hyperparamsearch/' + pdfname)\n","\n","#   loss = []\n","#   val_loss = []\n","#   train_si_snr = []\n","#   val_si_snr = []\n","#   for key in histories.keys():\n","#     loss.append(histories[key].history['loss'])\n","#     val_loss.append(histories[key].history['val_loss'])\n","#     train_si_snr.append(histories[key].history['si_snr'])\n","#     val_si_snr.append(histories[key].history['val_si_snr'])\n","#   loss         = np.concatenate(loss)\n","#   val_loss     = np.concatenate(val_loss)\n","#   train_si_snr = np.concatenate(train_si_snr)\n","#   val_si_snr   = np.concatenate(val_si_snr)\n","\n","#   best_val_epoch    = np.argmax(val_si_snr)\n","#   best_val_si_snr   = np.max(val_si_snr)\n","#   best_val_loss     = np.min(val_loss)\n","#   best_train_si_snr = np.max(train_si_snr)\n","#   best_train_loss   = np.min(loss)\n","\n","#   search_results.append({\n","#     **hyperParamSet,\n","#     'best_val_epoch': best_val_epoch,\n","#     'best_val_si_snr': best_val_si_snr,\n","#     'best_val_loss': best_val_loss,\n","#     'best_train_si_snr': best_train_si_snr,\n","#     'best_train_loss': best_train_loss\n","#   })\n","\n","\n","#   latest_results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n","\n","#   # Merge existing results and latest results\n","#   all_results = existing_results + latest_results\n","\n","#   # Write all results to the JSON file\n","#   with open(existing_file_path, 'w') as file:\n","#       json.dump(all_results, file, indent='')\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# # Merge existing results and latest results\n","# all_results = existing_results + latest_results\n","\n","# # Write all results to the JSON file\n","# with open(existing_file_path, 'w') as file:\n","#     json.dump(all_results, file, indent='')"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"zRzwd5jJ7Gj-"},"outputs":[],"source":["# \n","\n","# results = [{k: int(v) if isinstance(v, np.int64) else v for k, v in d.items()} for d in search_results]\n","\n","# with open(output_folder + 'hyperparamsearch/' + 'searchResults.json', 'w') as file:\n","#     json.dump(results, file, indent = '')"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# import import_ipynb\n","# from plot_hyperparameter import *\n","# hyperparameter_Plot(results, output_folder)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"fe4Pbw928oVb"},"outputs":[],"source":["####################################\n","#####  evaluate test songs\n","\n","# numTestSongs = 2\n","def evaluateTestSongs(autoencoder, num = 0):\n","  index = 0\n","  test_evaluated = []\n","  if num!=0:\n","    numTestSongs = num\n","  print(f'evaluating {numTestSongs} test songs')\n","  for songname in tqdm(reversed(fileNames[-numTestSongs:])):\n","      # songname = '1727_schubert_op114_2.wav'\n","      song = loadSong(songname)\n","      # wavfile.write(inpathOut + songname + '.wav', samplerate, song)\n","      songSnip = cut(song, snippitLength)\n","\n","      songSnip_transformed = MinMaxScaler().fit_transform(songSnip)\n","      test_loss, test_si_snr = autoencoder.evaluate(songSnip_transformed, songSnip_transformed, verbose=2)\n","\n","      test_evaluated.append([songname, test_loss, test_si_snr])\n","  return test_evaluated"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"_1XeEUQ-90bk"},"outputs":[{"name":"stdout","output_type":"stream","text":["4890/4890 [==============================] - 16s 3ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"ename":"NameError","evalue":"name 'testwav_si_snr' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[83], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m model_save_path \u001b[39m=\u001b[39m output_folder \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain_compression_rates/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_train_1_96_3.keras\u001b[39m\u001b[39m'\u001b[39m \u001b[39m#100\u001b[39;00m\n\u001b[1;32m     87\u001b[0m autoencoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(model_save_path)\n\u001b[0;32m---> 88\u001b[0m plotWave(autoencoder, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_folder\u001b[39m}\u001b[39;49;00m\u001b[39mtrain_compression_rates/model_0.2_1_96_3wave_\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0.2\u001b[39;49m)\n","Cell \u001b[0;32mIn[83], line 36\u001b[0m, in \u001b[0;36mplotWave\u001b[0;34m(autoencoder, name, compression_ratio)\u001b[0m\n\u001b[1;32m     32\u001b[0m Xpred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(XpredSnip_minussilence)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint16\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m output_wav_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msnln=\u001b[39m\u001b[39m{\u001b[39;00msnippitLength\u001b[39m}\u001b[39;00m\u001b[39m_cmpr=\u001b[39m\u001b[39m{\u001b[39;00mcompression_ratio\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_loss=\u001b[39m\u001b[39m{\u001b[39;00mloss_fct\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_SNR=\u001b[39m\u001b[39m{\u001b[39;00mtestwav_si_snr\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     37\u001b[0m wavfile\u001b[39m.\u001b[39mwrite(output_folder \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39moriginal.wav\u001b[39m\u001b[39m'\u001b[39m, samplerate, orig)\n\u001b[1;32m     38\u001b[0m wavfile\u001b[39m.\u001b[39mwrite(output_folder \u001b[39m+\u001b[39m output_wav_name, samplerate, Xpred)\n","\u001b[0;31mNameError\u001b[0m: name 'testwav_si_snr' is not defined"]}],"source":["####################################\n","#####  predict unknown song\n","\n","def plotWave(autoencoder, name, compression_ratio):\n","  exampleSong = fileNames[-1]\n","  # exampleSong = '1727_schubert_op114_2.wav'\n","  orig = loadSong(exampleSong)\n","  origSnip = cut(orig, snippitLength)\n","  orig = np.concatenate(origSnip)\n","\n","  if(exampleSong in scaler.keys()):\n","    scaler_Example = scaler[exampleSong]\n","    origSnip_transformed = scaler_Example.transform(origSnip)\n","  else:\n","    scaler_Example = MinMaxScaler()\n","    origSnip_transformed = scaler_Example.fit_transform(origSnip)\n","\n","  # autoencode song\n","  a = autoencoder.predict(origSnip_transformed)\n","  a = a.reshape(-1, snippitLength)\n","  XpredSnip = scaler_Example.inverse_transform(a)\n","\n","  silence = np.zeros((1,snippitLength), dtype = 'int16')\n","  a = scaler_Example.transform(silence)\n","  a = autoencoder.predict(a)\n","  a = a.reshape(-1, snippitLength)\n","  Xsilence = scaler_Example.inverse_transform(a)[0]\n","\n","  # remove noise generated by silence\n","  # XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n","  XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n","  Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')\n","\n","  # test_loss, test_si_snr = autoencoder.evaluate(origSnip_transformed, origSnip_transformed\n","  testwav_si_snr = si_snr_std(orig, Xpred)\n","\n","  output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n","  wavfile.write(output_folder + 'original.wav', samplerate, orig)\n","  wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n","  print(f\"file saved: {output_wav_name}\")\n","\n","  plt.plot(orig, linewidth = 0.1)\n","  plt.plot(orig-Xpred, linewidth = 0.1)\n","  plt.savefig(name + \"whole.pdf\")\n","  plt.clf()\n","  ####################################\n","  #####  see difference in waveform detailed\n","  nrows = 2\n","  ncols = 6\n","  snips = [0, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n","\n","  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n","  s = 0\n","  for i in range(nrows):\n","    for j in range(ncols):\n","      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n","      ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n","      s +=1\n","  plt.savefig(name + \"snip_corrected.pdf\")\n","  plt.clf()\n","\n","  fig, ax = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows), sharey = True, sharex = True)\n","  s = 0\n","  for i in range(nrows):\n","    for j in range(ncols):\n","      ax[i][j].plot(origSnip[snips[s]], linewidth = 0.5, c = 'b')\n","      ax[i][j].plot(XpredSnip[snips[s]], linewidth = 0.5, c = 'r')\n","      # ax[i][j].plot(XpredSnip_minussilence[snips[s]], linewidth = 0.5, c = 'r')\n","      s +=1\n","  plt.savefig(name + \"snip_notcorrected.pdf\")\n","  plt.clf()\n","\n","\n","def si_snr_std(original, estimate):\n","  dot = np.sum(original * estimate, axis=-1, keepdims=True)\n","  # compute the energy of target along the time axis\n","  denominator = np.sum(original ** 2, axis=-1, keepdims=True)\n","  # compute the scaled target\n","  scaled_target = dot * original / denominator\n","  # compute the noise\n","  e_noise = estimate - scaled_target\n","  # compute the SI-SNR in decibels\n","  si_snr = 10 * np.log10(np.sum(scaled_target ** 2, axis=-1) / np.sum(e_noise ** 2, axis=-1))\n","  # return the SI-SNR array of shape (batch_size,)\n","  return si_snr\n","\n","model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n","autoencoder = tf.keras.models.load_model(model_save_path)\n","plotWave(autoencoder, f'{output_folder}train_compression_rates/model_0.2_1_96_3wave_', 0.2)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4890/4890 [==============================] - 16s 3ms/step\n","1/1 [==============================] - 0s 17ms/step\n"]}],"source":["model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n","\n","exampleSong = fileNames[-1]\n","orig = loadSong(exampleSong)\n","origSnip = cut(orig, snippitLength)\n","orig = np.concatenate(origSnip)\n","\n","if(exampleSong in scaler.keys()):\n","  scaler_Example = scaler[exampleSong]\n","  origSnip_transformed = scaler_Example.transform(origSnip)\n","else:\n","  scaler_Example = MinMaxScaler()\n","  origSnip_transformed = scaler_Example.fit_transform(origSnip)\n","\n","# autoencode song\n","autoencoder = tf.keras.models.load_model(model_save_path)\n","a = autoencoder.predict(origSnip_transformed)\n","a = a.reshape(-1, snippitLength)\n","XpredSnip = scaler_Example.inverse_transform(a)\n","\n","silence = np.zeros((1,snippitLength), dtype = 'int16')\n","a = scaler_Example.transform(silence)\n","a = autoencoder.predict(a)\n","a = a.reshape(-1, snippitLength)\n","Xsilence = scaler_Example.inverse_transform(a)[0]\n","\n","# remove noise generated by silence\n","# XpredSnip_minussilence = [i-Xsilence for i in XpredSnip]\n","XpredSnip_minussilence = np.array(XpredSnip) - Xsilence\n","Xpred = np.concatenate(XpredSnip_minussilence).astype('int16')"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ucorrected SI-SNR -4.526547700446205 dB\n","corrected SI-SNR 12.08536407144872 dB\n"]}],"source":["estimate_uncorr = np.concatenate(XpredSnip).astype('int16')\n","estimate_corr = Xpred\n","original = orig\n","\n","uncorr = si_snr_std(original, estimate_uncorr)\n","print(f'ucorrected SI-SNR {uncorr} dB')\n","\n","corr = si_snr_std(original, estimate_corr)\n","print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d2 = np.array(original) - 0.1\n","# corr = si_snr_std(original, original_d2)\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d2 = np.array(original) + 1\n","# corr = si_snr_std(original, original_d2)\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# original_d = [i+0.01 for i in original]\n","# corr = si_snr_std(original, np.concatenate(original_d).astype('int16'))\n","# print(f'corrected SI-SNR {corr} dB')\n","\n","# output_wav_name = f'snln={snippitLength}_cmpr={compression_ratio:.1f}_loss={loss_fct.__name__}_SNR={testwav_si_snr:.1f}.wav'\n","# wavfile.write(output_folder + 'original.wav', samplerate, orig)\n","# wavfile.write(output_folder + output_wav_name, samplerate, Xpred)\n"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["(156470, 64)"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["XpredSnip.shape"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["(dtype('int16'), dtype('int16'), dtype('int16'))"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["original.dtype, estimate_uncorr.dtype, estimate_corr.dtype"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"_XQYjrwo7IcC"},"outputs":[{"ename":"SyntaxError","evalue":"'break' outside loop (3651145951.py, line 81)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[26], line 81\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"]}],"source":["# Find best topology across different compression ratios and build/train 10 models across compression ratios with that topology\n","import csv\n","\n","def read_histories_from_csv(file_path):\n","    histories = {}\n","    with open(file_path, 'r') as csvfile:\n","        reader = csv.reader(csvfile)\n","        next(reader)  # Skip the header row\n","        for row in reader:\n","            filename = row[0]\n","            loss = float(row[1])\n","            val_loss = float(row[2])\n","            histories[filename] = {'loss': [loss], 'val_loss': [val_loss]}\n","    return histories\n","\n","# tf.random.set_seed(42+300)\n","\n","parSet_sum = {}\n","search_results_json = output_folder + 'hyperparamsearch/' + 'searchResults.json'\n","search_results_json = 'output/Versuch1_11.07.2023/searchResults.json'\n","search_results_json = 'output/Versuch3_13.07.2023/hyperparamsearch/searchResults_170songs_5epochs_final.json'\n","with open(search_results_json, 'r') as file:\n","    search_results = json.load(file)\n","\n","for item in search_results:\n","    numDense = item['numDense']\n","    numConv = item['numConv']\n","    numConvLayer = item['numConvLayer']\n","    best_val_si_snr = item['best_val_si_snr']\n","\n","    key = (numDense, numConv, numConvLayer)\n","    if key in parSet_sum:\n","       parSet_sum[key] += best_val_si_snr\n","    else:\n","        parSet_sum[key] = best_val_si_snr\n","\n","keys = [k for k in parSet_sum.keys()]\n","si_snr_sum = [parSet_sum[k] for k in keys]\n","bestParSet = keys[np.argmax(si_snr_sum)]\n","# print(f'best set : {bestParSet}')\n","\n","# compression_rates = np.linspace(0.1,0.9,9) # todo\n","compression_rates = [0.2]\n","# silence_prob = 0.01\n","\n","numTopoTrainSongs = 1 # 6 min \n","numTopoEpochs = 1\n","\n","numTotalSongs = 17\n","percentage_of_song = float(1/(numTotalSongs))\n","\n","total_num_songs = len(fileNames)\n","numTopoTrainSongs = int(((total_num_songs*0.7)+1))\n","# numTopoTrainSongs = numTopoTrainSongs*4\n","numTopoEpochs = 1\n","\n","learning_rate = 0.1 # nooo\n","learning_rate = 0.01 # nooo\n","learning_rate = 0.0001 #no\n","learning_rate = 0.0005\n","learning_rate = 0.005  # 20\n","learning_rate = 0.003  # 36\n","learning_rate = 0.0004  # better and slow up trend should be ok\n","learning_rate = 0.0008  # better and slow up trend\n","learning_rate = 0.0004 #no\n","learning_rate = 0.001 #30 ish\n","learning_rate = 0.0006  # better and slow up trend\n","learning_rate = 0.0002 #no\n","learning_rate = 0.00008 #no\n","\n","numTestSongs = int(total_num_songs*0.3)\n","model_save_path = output_folder + 'hyperparamsearch/' + f'model_train1_1024_5.keras' #20\n","model_save_path = output_folder + 'hyperparamsearch/' + f'model_train1_256_3.keras' #20\n","model_save_path = output_folder + 'train_compression_rates/' + f'model_train1_128_3.keras' #20\n","model_save_path = output_folder + 'train_compression_rates/' + f'model_train_1_96_3.keras' #100\n","histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train1_128_3.csv'\n","histories_save_path = output_folder + 'train_compression_rates/' + 'histories_train_1_96_3.csv'\n","def lr_schedule(epoch):\n","  return learning_rate\n","autoencoder = tf.keras.models.load_model(model_save_path)\n","# break\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","for c in compression_rates:\n","  # autoencoder = buildModel(c, bestParSet[0],bestParSet[1],bestParSet[2], learning_rate = learning_rate)\n","  # autoencoder = buildModel(c, 1, 96, 3, learning_rate = learning_rate)\n","  autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","  histories = {}\n","  batch_size=512\n","  batch_size=2**12\n","  batch_size=2**8  #256\n","  batch_size=2**7  #128 # train and val diverging by +0.1\n","  batch_size=2**6  #64\n","  for idx, filename_train in tqdm(enumerate(fileNames[120:numTopoTrainSongs:])):\n","    Xt, Xv = loadSongCut(filename_train, numTotalSongs = numTotalSongs, percentage_of_song = percentage_of_song)\n","    histories[filename_train] = autoencoder.fit(Xt, Xt,\n","                epochs=numTopoEpochs,\n","                batch_size=batch_size,\n","                shuffle=True,\n","                validation_data=(Xv, Xv),\n","                callbacks=[lr_scheduler])\n","    del Xt\n","    del Xv\n","    save_period = int(9/numHyperEpochs)\n","    save_period = 1\n","    if (idx % save_period == 0) and (idx != 0):\n","      autoencoder.save(model_save_path)\n","      del autoencoder\n","      autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","      with open(histories_save_path, 'w', newline='') as csvfile:\n","          writer = csv.writer(csvfile)\n","          writer.writerow(['filename', 'loss', 'val_loss'])\n","          for key, value in histories.items():\n","              writer.writerow([key, value.history['loss'][0], value.history['val_loss'][0]], value.history['loss'][0])\n","  tf.keras.backend.clear_session()\n","  \n","  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n","  histories = read_histories_from_csv(histories_save_path)\n","  plot_history(histories, output_folder + 'train_compression_rates/' + pdfname)\n","  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n","\n","  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n","  testPerformance = evaluateTestSongs(autoencoder, num = 1)\n","\n","  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n","    # Create a CSV writer\n","    writer = csv.writer(file)\n","\n","    # Write the data row by row\n","    for row in testPerformance:\n","        writer.writerow(row)\n","\n","  break\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["0.05"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["numTotalSongs = 20\n","percentage_of_song = 1/(numTotalSongs)\n","percentage_of_song"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4890/4890 [==============================] - 18s 3ms/step\n","1/1 [==============================] - 0s 320ms/step\n","4890/4890 [==============================] - 20s 4ms/step - loss: 0.0194 - si_snr: 30.7520\n","file saved: snln=64_cmpr=0.2_loss=snipLoss_songs=170_SNR=30.8.wav\n"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 3600x1200 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 3600x1200 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["autoencoder = tf.keras.models.load_model(model_save_path)\n","\n","plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{0.2:.1f}wave_', 0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["  for filename_train in tqdm(fileNames[:numTopoTrainSongs]):\n","    Xt, Xv = loadSongCut(filename_train, silence_prob = silence_prob)\n","    histories[filename_train] = autoencoder.fit(Xt, Xt,\n","                epochs=numTopoEpochs,\n","                batch_size=2**10,\n","                shuffle=True,\n","                validation_data=(Xv, Xv))\n","    \n","  pdfname = f'BestSet, compression_ratio ={c:.1f}.pdf'\n","  plot_history(histories, output_folder + 'train_compression_rates/' + pdfname)\n","\n","  autoencoder.save(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}.keras')\n","  testPerformance = evaluateTestSongs(autoencoder)\n","\n","  with open(f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}Performance.csv', 'w', newline='') as file:\n","    # Create a CSV writer\n","    writer = csv.writer(file)\n","\n","    # Write the data row by row\n","    for row in testPerformance:\n","        writer.writerow(row)\n","  plotWave(autoencoder, f'{output_folder}train_compression_rates/modelCompressionRate:{c:.1f}wave_', c)\n","\n","  break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgKZrEl6CGnU","tags":["fit"]},"outputs":[],"source":["# #numTrainSongs =\n","# batch_size = 2**10\n","# epochs = 5\n","# histories = {}\n","# for fn in tqdm(fileNames[:numTrainSongs]):\n","#   Xt, Xv = loadSongCut(fn)\n","#   Xt = np.array(Xt)\n","#   Xv = np.array(Xv)\n","#   histories[fn] = autoencoder.fit(Xt, Xt,\n","#                 epochs=epochs,\n","#                 batch_size=batch_size,\n","#                 shuffle=True,\n","#                 validation_data=(Xv, Xv))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
